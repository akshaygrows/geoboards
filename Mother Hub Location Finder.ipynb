{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "16b3f22a-ca78-4759-a1fa-2351ec51548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "import psycopg2 as psy\n",
    "import pandas as pd\n",
    "from IPython.display import FileLink\n",
    "import geopandas as gpd\n",
    "import plotly.express as px\n",
    "from dash import Dash, dcc, html, Input, Output\n",
    "import paramiko\n",
    "from io import StringIO\n",
    "from shapely.geometry import MultiPoint, MultiPolygon\n",
    "import scipy\n",
    "import scipy.cluster\n",
    "from shapely.ops import unary_union\n",
    "import calendar\n",
    "from datetime import datetime\n",
    "from geopy.distance import great_circle\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1063cd24-77af-4bb3-86d5-3cbd2f8b401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establishing connection with datawarehouse\n",
    "def get_conn_postgres(SSH_required,key_path):\n",
    "\n",
    "    db='datawarehouse'\n",
    "    DB_HOST='datawarehouse.cdgpvetprks3.ap-south-1.rds.amazonaws.com'\n",
    "    conn = []\n",
    "    if SSH_required == 'Yes':\n",
    "        SSH_HOST='ec2-15-206-161-154.ap-south-1.compute.amazonaws.com'\n",
    "        #LOCALHOST=\"0.0.0.0\"\n",
    "        ssh_tunnel= SSHTunnelForwarder(\n",
    "                (SSH_HOST, 22),\n",
    "                ssh_username=\"ec2-user\",\n",
    "                ssh_private_key= key_path,\n",
    "                ssh_private_key_password= \"\",\n",
    "                remote_bind_address=(DB_HOST, 5432),\n",
    "                local_bind_address=('127.0.0.1', 0)\n",
    "        )\n",
    "        print('Tunnel Started')\n",
    "        ssh_tunnel.start()\n",
    "        conn = psy.connect(\n",
    "            host=ssh_tunnel.local_bind_host,\n",
    "            port=ssh_tunnel.local_bind_port,\n",
    "            user='postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        print('Connection Made')\n",
    "        return conn\n",
    "    else:\n",
    "        conn = psy.connect(\n",
    "            host = DB_HOST,\n",
    "            port = 5432,\n",
    "            user = 'postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        print('Connection Made')\n",
    "        return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9718aab1-049a-4246-8b89-ffd7cd0240ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting dataframe from datawarehouse\n",
    "def get_df_from_sql_postgres(SSH_required, query,key_path):   #for getting a datafarame as a result\n",
    "\n",
    "    db='datawarehouse'\n",
    "    DB_HOST='datawarehouse.cdgpvetprks3.ap-south-1.rds.amazonaws.com'\n",
    "    conn = None\n",
    "    if SSH_required == 'Yes':\n",
    "        SSH_HOST='ec2-15-206-161-154.ap-south-1.compute.amazonaws.com'\n",
    "        #LOCALHOST=\"0.0.0.0\"\n",
    "        ssh_tunnel= SSHTunnelForwarder(\n",
    "                (SSH_HOST, 22),\n",
    "                ssh_username=\"ec2-user\",\n",
    "                ssh_private_key= key_path,\n",
    "                ssh_private_key_password= \"\",\n",
    "                remote_bind_address=(DB_HOST, 5432),\n",
    "                local_bind_address=('127.0.0.1', 0)\n",
    "        )\n",
    "        # ssh_tunnel._server_list[0].block_on_close = False\n",
    "        ssh_tunnel.start()\n",
    "        conn = psy.connect(\n",
    "            host=ssh_tunnel.local_bind_host,\n",
    "            port=ssh_tunnel.local_bind_port,\n",
    "            user='postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        df_results = pd.read_sql(query, conn)\n",
    "        conn.close()\n",
    "        ssh_tunnel.stop()\n",
    "        return df_results\n",
    "    else:\n",
    "        conn = psy.connect(\n",
    "            host = DB_HOST,\n",
    "            port = 5432,\n",
    "            user = 'postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        df_results = pd.read_sql(query, conn)\n",
    "        conn.close()\n",
    "        return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f2a46bf0-7ee5-4980-a0a5-dd4a9d20ebee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunnel Started\n",
      "Connection Made\n",
      "                                      warehouse_name last_mile_hub  orders\n",
      "0  15 Ground Floor, SY No  131 3, Hoskote, Anjane...          BLDR      97\n",
      "1  15 Ground Floor, SY No  131 3, Hoskote, Anjane...          CMRJ      11\n",
      "2  15 Ground Floor, SY No  131 3, Hoskote, Anjane...          ECTY      44\n",
      "3  15 Ground Floor, SY No  131 3, Hoskote, Anjane...          HBBL      45\n",
      "4  15 Ground Floor, SY No  131 3, Hoskote, Anjane...          JPNR     100\n"
     ]
    }
   ],
   "source": [
    "#Getting Ops Main Data for last 30 days\n",
    "SSH_required = 'Yes'\n",
    "key_path = '/home/rajat/Downloads/tunnel-ssh .cer'\n",
    "query = \"select warehouse_name, last_mile_hub, count(*) as orders from public.ops_main where date_trunc('month', created_date) >= date_trunc('month', now() - interval'1 month') and shipping_partner = 'Hyperlocal' and shipping_city = 'Bangalore' and warehouse_city = 'Bangalore' group by warehouse_name, last_mile_hub;\"\n",
    "# Establish a connection\n",
    "conn = get_conn_postgres(SSH_required, key_path)\n",
    "\n",
    "# Retrieve data into a DataFrame\n",
    "df_ops_main = get_df_from_sql_postgres(SSH_required, query, key_path)\n",
    "\n",
    "# Now you can perform further operations with the DataFrame\n",
    "print(df_ops_main.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "151d4022-96e8-4906-afb9-c2357a8cdfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting client warehouse lat longs for BLR\n",
    "df_warehouse = pd.read_csv('warehouses_w_lat_lng_blr.csv')\n",
    "df_warehouse['lat_long'] = df_warehouse['lat_long'].apply(eval)\n",
    "# print(df_warehouse.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7c02105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting hub lat longs for BLR\n",
    "df_hubs = pd.read_csv('hubs_w_lat_lng_blr.csv')\n",
    "df_hubs['last_mile_hub'] = df_hubs['sort_codes'].str.split('/').str[1].str.strip()\n",
    "df_hubs['lat_long'] = df_hubs['lat_long'].apply(eval)\n",
    "# print(df_hubs.head())dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d0a076fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        warehouse_name last_mile_hub  orders  \\\n",
      "0    15 Ground Floor, SY No  131 3, Hoskote, Anjane...          BLDR      97   \n",
      "1    15 Ground Floor, SY No  131 3, Hoskote, Anjane...          CMRJ      11   \n",
      "2    15 Ground Floor, SY No  131 3, Hoskote, Anjane...          ECTY      44   \n",
      "3    15 Ground Floor, SY No  131 3, Hoskote, Anjane...          HBBL      45   \n",
      "4    15 Ground Floor, SY No  131 3, Hoskote, Anjane...          JPNR     100   \n",
      "..                                                 ...           ...     ...   \n",
      "475                                   Vaaree Warehouse          JPNR      51   \n",
      "476                                   Vaaree Warehouse          MRTH      51   \n",
      "477                                   Vaaree Warehouse          STNG      10   \n",
      "478                                   Vaaree Warehouse          UTTR      27   \n",
      "479                                   Vaaree Warehouse          YLHK       8   \n",
      "\n",
      "                 warehouse_lat_long                     hub_lat_long  \n",
      "0          [13.0692593, 77.7982428]         [12.9394122, 77.6921294]  \n",
      "1          [13.0692593, 77.7982428]         [12.9467756, 77.5519109]  \n",
      "2          [13.0692593, 77.7982428]         [12.8307773, 77.6612892]  \n",
      "3          [13.0692593, 77.7982428]          [13.0405585, 77.595625]  \n",
      "4          [13.0692593, 77.7982428]  [12.9144032, 77.59958150000001]  \n",
      "..                              ...                              ...  \n",
      "475  [13.057298, 77.69993649999999]  [12.9144032, 77.59958150000001]  \n",
      "476  [13.057298, 77.69993649999999]         [12.9497375, 77.6982656]  \n",
      "477  [13.057298, 77.69993649999999]  [12.9594816, 77.59276179999999]  \n",
      "478  [13.057298, 77.69993649999999]  [12.8743079, 77.55229159999999]  \n",
      "479  [13.057298, 77.69993649999999]          [13.0725756, 77.592424]  \n",
      "\n",
      "[480 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Adding lat long data to Ops Main, making dataframe 'orders'\n",
    "\n",
    "#warehouse lat long\n",
    "df_merged = pd.merge(df_ops_main, df_warehouse[['warehouse_name', 'lat_long']], on='warehouse_name', how='left')\n",
    "df_merged.rename(columns={'lat_long': 'warehouse_lat_long'}, inplace=True)\n",
    "# print(df_merged.head())\n",
    "\n",
    "# hub lat long\n",
    "orders = pd.merge(df_merged, df_hubs[['last_mile_hub', 'lat_long']], on='last_mile_hub', how='left')\n",
    "orders.rename(columns={'lat_long': 'hub_lat_long'}, inplace=True)\n",
    "\n",
    "print(orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "06098a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<class 'float'>}\n",
      "9      NaN\n",
      "10     NaN\n",
      "11     NaN\n",
      "12     NaN\n",
      "13     NaN\n",
      "      ... \n",
      "466    NaN\n",
      "467    NaN\n",
      "468    NaN\n",
      "469    NaN\n",
      "470    NaN\n",
      "Name: warehouse_lat_long, Length: 279, dtype: object\n",
      "['16   1, Deganhalli Village Road, Kasaba Hobli,'\n",
      " '24 2, Chikkahullur Village, Kasba Hobli,' 'Asitis BLR2'\n",
      " 'BLR Adret Retail' 'BNG - Bengaluru' 'BOAT Bangalore' 'BVO Bangalore'\n",
      " 'Decathlon BLR' 'DS_blr_mtl_HK' 'EASYECOM-RDCBLRFC4'\n",
      " 'Emiza supply chain services Pvt Ltd survey no 83 2 Kachanahalli Beside Kirloskar Electric company Budhihall post Nelmangala'\n",
      " 'GIVA DEL' 'HK BLR'\n",
      " 'Honasa Consumer Limited Emiza Bangalore Aqua, C O Emiza Supply chain service Pvt Ltd,Sy no 83 1,Kachanahalli village, Buddihal post, Kasaba Hobli, Nelamagala ta'\n",
      " 'Katha no 461 100 7, Comprised of Converted Survey No 100 4, Reserve Survey No'\n",
      " 'Manash Bangalore Warehouse'\n",
      " 'Mathru Shree Warehouse,Survey No 83 2 ,Kachanahalli' 'Minimalist'\n",
      " 'Mokobara Lifestyle Pvt Ltd' 'MW_Bangalore' 'Neemans Private Limited'\n",
      " 'NO  33 34,1st FLOOR, BESIDE PF OFFICE , HOSUR ROAD I SINGASANDRA, BANGALORE 560068'\n",
      " 'OZiva BLR' 'Plum' 'Plum Bangalore' 'Prozo Bangalore'\n",
      " 'Snitch Apparels Pvt Ltd' 'SNITCH APPARELS PVT LTD NEL' 'SSDC BNG'\n",
      " 'Survey No 1 1B, 1 2P, Gangadharanapalya Village Kasaba Hobli'\n",
      " 'Sy  No  58, Malonagathihalli Village'\n",
      " 'Trusource Technology Private Limited' 'TSS BLR']\n"
     ]
    }
   ],
   "source": [
    "#Analysing Warehouse Lat Long Data\n",
    "other_datatypes = set()\n",
    "for coords in orders['warehouse_lat_long']:\n",
    "    datatype = type(coords)\n",
    "    if datatype != list:\n",
    "        other_datatypes.add(datatype)\n",
    "\n",
    "print(other_datatypes)\n",
    "\n",
    "float_values = orders[orders['warehouse_lat_long'].apply(lambda x: isinstance(x, float))]\n",
    "print(float_values['warehouse_lat_long'])\n",
    "\n",
    "# Filter the DataFrame to only include rows where warehouse_lat_long is NaN\n",
    "nan_values = orders[orders['warehouse_lat_long'].apply(lambda x: isinstance(x, float) and pd.isna(x))]\n",
    "print(nan_values['warehouse_name'].unique())\n",
    "\n",
    "# Filter the DataFrame to only include rows where warehouse_lat_long is NaN\n",
    "nan_values = orders[orders['warehouse_lat_long'].apply(lambda x: isinstance(x, float) and pd.isna(x))]\n",
    "\n",
    "# Get unique warehouse names\n",
    "unique_warehouse_names = nan_values['warehouse_name'].unique()\n",
    "\n",
    "# Create a DataFrame with unique warehouse names\n",
    "unique_warehouse_df = pd.DataFrame({'warehouse_name': unique_warehouse_names})\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "unique_warehouse_df.to_excel('not_in_warehouses_warehouse.xlsx', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "99478300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Warehouse Lat Long Data, for non-NaN values in the warehouse_lat_long column\n",
    "filtered_orders = orders.dropna(subset=['warehouse_lat_long'])\n",
    "# Save the filtered DataFrame to a new variable named \"orders\"\n",
    "orders = filtered_orders.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b13c7e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<class 'float'>}\n",
      "29     NaN\n",
      "47     NaN\n",
      "114    NaN\n",
      "212    NaN\n",
      "222    NaN\n",
      "232    NaN\n",
      "252    NaN\n",
      "405    NaN\n",
      "Name: hub_lat_long, dtype: object\n",
      "['MTH']\n"
     ]
    }
   ],
   "source": [
    "##Analysing Hub Lat Long Data\n",
    "other_datatypes = set()\n",
    "for coords in orders['hub_lat_long']:\n",
    "    datatype = type(coords)\n",
    "    if datatype != list:\n",
    "        other_datatypes.add(datatype)\n",
    "\n",
    "print(other_datatypes)\n",
    "\n",
    "float_values = orders[orders['hub_lat_long'].apply(lambda x: isinstance(x, float))]\n",
    "print(float_values['hub_lat_long'])\n",
    "\n",
    "# Filter the DataFrame to only include rows where hub_lat_long is NaN\n",
    "nan_values = orders[orders['hub_lat_long'].apply(lambda x: isinstance(x, float) and pd.isna(x))]\n",
    "print(nan_values['last_mile_hub'].unique())\n",
    "\n",
    "# Filter the DataFrame to only include rows where hub_lat_long is NaN\n",
    "nan_values = orders[orders['hub_lat_long'].apply(lambda x: isinstance(x, float) and pd.isna(x))]\n",
    "\n",
    "# Get unique warehouse names\n",
    "unique_warehouse_names = nan_values['last_mile_hub'].unique()\n",
    "\n",
    "# Create a DataFrame with unique warehouse names\n",
    "unique_warehouse_df = pd.DataFrame({'last_mile_hub': unique_warehouse_names})\n",
    "\n",
    "# # Save the DataFrame to an Excel file\n",
    "# unique_warehouse_df.to_excel('not_in_warehouses_warehouse.xlsx', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7199d343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Hub Lat Long Data, for non-NaN values in the hub_lat_long column\n",
    "filtered_orders = orders.dropna(subset=['hub_lat_long'])\n",
    "\n",
    "# Save the filtered DataFrame to a new variable named \"orders\"\n",
    "orders = filtered_orders.copy()\n",
    "\n",
    "# print(orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "02c7f320-9a28-437c-ae86-6f4c0e27f23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12.9497375, 77.6982656)\n"
     ]
    }
   ],
   "source": [
    "#Defining the Fixed Motherhub\n",
    "\n",
    "# Retrieve lat_long column for central_hub nodes\n",
    "fixed_motherhub = df_hubs[df_hubs['node_type'] == 'central_hub']['lat_long']\n",
    "\n",
    "# Access latitude and longitude values from the first row\n",
    "fixed_motherhub_latitude = fixed_motherhub.iloc[0][0]\n",
    "fixed_motherhub_longitude = fixed_motherhub.iloc[0][1]\n",
    "\n",
    "# Create a tuple with latitude and longitude values\n",
    "fixed_motherhub = (fixed_motherhub_latitude, fixed_motherhub_longitude)\n",
    "\n",
    "# Print the fixed_motherhub coordinates\n",
    "print(fixed_motherhub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "54cdb296-fb0a-47cf-8906-332099f24a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost should not go above a limit\n",
    "#cost can be defined with rwith centre as centre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "88cf6b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Guess: (12.989052356476684, 77.6143475865285)\n",
      "Initial Total Distance: 960301.6539781998\n",
      "Optimal New Motherhub Location: [12.93524881 77.58228153]\n",
      "Total Distance: 844947.7365317116\n"
     ]
    }
   ],
   "source": [
    "#Defining function for total distance\n",
    "def total_distance(new_motherhub, orders, fixed_motherhubs):\n",
    "    total_dist = 0\n",
    "\n",
    "    for _, row in orders.iterrows():\n",
    "        client_latitude = row['warehouse_lat_long'][0]\n",
    "        client_longitude = row['warehouse_lat_long'][1]\n",
    "        client_location = (client_latitude, client_longitude)\n",
    "\n",
    "        last_mile_latitude = row['hub_lat_long'][0]\n",
    "        last_mile_longitude = row['hub_lat_long'][1]\n",
    "        last_mile_location = (last_mile_latitude, last_mile_longitude)\n",
    "        \n",
    "        for fixed_motherhub in fixed_motherhubs:\n",
    "            dist_client_to_fixed = great_circle(client_location, fixed_motherhub).km\n",
    "            dist_fixed_to_last_mile = great_circle(fixed_motherhub, last_mile_location).km\n",
    "            total_dist_fixed = dist_client_to_fixed + dist_fixed_to_last_mile\n",
    "            \n",
    "            dist_client_to_new = great_circle(client_location, tuple(new_motherhub)).km\n",
    "            dist_new_to_last_mile = great_circle(tuple(new_motherhub), last_mile_location).km\n",
    "            total_dist_new = dist_client_to_new + dist_new_to_last_mile\n",
    "            \n",
    "            total_dist += row['orders'] * min(total_dist_fixed, total_dist_new)\n",
    "    \n",
    "    return total_dist\n",
    "\n",
    "# Calculate the mean latitude and longitude separately\n",
    "mean_latitude = orders['warehouse_lat_long'].apply(lambda x: x[0]).mean()\n",
    "mean_longitude = orders['warehouse_lat_long'].apply(lambda x: x[1]).mean()\n",
    "\n",
    "# Create the initial guess tuple\n",
    "initial_guess = (mean_latitude, mean_longitude)\n",
    "print(\"Initial Guess:\", initial_guess)\n",
    "\n",
    "# Calculate the initial total distance with the initial guess\n",
    "initial_total_dist = total_distance(initial_guess, orders, [fixed_motherhub])\n",
    "print(\"Initial Total Distance:\", initial_total_dist)\n",
    "\n",
    "# Apply the optimization\n",
    "result = minimize(total_distance, initial_guess, args=(orders, [fixed_motherhub]), method='Nelder-Mead')\n",
    "\n",
    "# Print the result\n",
    "# print(\"Optimization Result:\", result)\n",
    "optimal_new_motherhub_location = result.x\n",
    "print(\"Optimal New Motherhub Location:\", optimal_new_motherhub_location)\n",
    "print(\"Total Distance:\", result.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b0413bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the Mother Hub assigned\n",
    "\n",
    "# Access latitude and longitude values of new motherhub\n",
    "optimal_new_motherhub_latitude = optimal_new_motherhub_location[0]\n",
    "optimal_new_motherhub_longitude = optimal_new_motherhub_location[1]\n",
    "\n",
    "# Create a tuple with latitude and longitude values\n",
    "new_motherhub = (optimal_new_motherhub_latitude, optimal_new_motherhub_longitude)\n",
    "\n",
    "motherhub_labels = []\n",
    "\n",
    "# Loop through each order and determine whether it passes through the fixed or new motherhub\n",
    "for _, row in orders.iterrows():\n",
    "    client_latitude = row['warehouse_lat_long'][0]\n",
    "    client_longitude = row['warehouse_lat_long'][1]\n",
    "    client_location = (client_latitude, client_longitude)\n",
    "\n",
    "    last_mile_latitude = row['hub_lat_long'][0]\n",
    "    last_mile_longitude = row['hub_lat_long'][1]\n",
    "    last_mile_location = (last_mile_latitude, last_mile_longitude)\n",
    "    \n",
    "    dist_client_to_fixed = great_circle(client_location, fixed_motherhub).km\n",
    "    dist_fixed_to_last_mile = great_circle(fixed_motherhub, last_mile_location).km\n",
    "    total_dist_fixed = dist_client_to_fixed + dist_fixed_to_last_mile\n",
    "    \n",
    "    dist_client_to_new = great_circle(client_location, tuple(new_motherhub)).km\n",
    "    dist_new_to_last_mile = great_circle(tuple(new_motherhub), last_mile_location).km\n",
    "    total_dist_new = dist_client_to_new + dist_new_to_last_mile\n",
    "    \n",
    "    if total_dist_fixed < total_dist_new:\n",
    "        motherhub_labels.append('Fixed')\n",
    "    else:\n",
    "        motherhub_labels.append('New')\n",
    "\n",
    "# Add the list of labels as a new column in the orders DataFrame\n",
    "orders['motherhub_label'] = motherhub_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3da4b896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "file_path = \"orders.xlsx\"\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "orders.to_excel(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "775cd79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8051/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x79a871daad10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the app\n",
    "app = Dash(__name__)\n",
    "\n",
    "# Define app layout\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Motherhub Locations\", style={'text-align': 'center'}),\n",
    "    dcc.Graph(\n",
    "        id='map',\n",
    "        figure={\n",
    "            'data': [\n",
    "                # Trace for fixed motherhub\n",
    "                {\n",
    "                    'type': 'scattermapbox',\n",
    "                    'lat': [fixed_motherhub[0]],  # Fixed motherhub latitude\n",
    "                    'lon': [fixed_motherhub[1]],  # Fixed motherhub longitude\n",
    "                    'mode': 'markers',\n",
    "                    'marker': {\n",
    "                        'size': 12,\n",
    "                        'color': 'green'  # Set color for fixed motherhub\n",
    "                    },\n",
    "                    'name': 'Fixed Motherhub'\n",
    "                },\n",
    "                # Trace for optimal new motherhub location\n",
    "                {\n",
    "                    'type': 'scattermapbox',\n",
    "                    'lat': [optimal_new_motherhub_location[0]],  # Optimal new motherhub latitude\n",
    "                    'lon': [optimal_new_motherhub_location[1]],  # Optimal new motherhub longitude\n",
    "                    'mode': 'markers',\n",
    "                    'marker': {\n",
    "                        'size': 12,\n",
    "                        'color': 'blue'  # Set color for optimal new motherhub location\n",
    "                    },\n",
    "                    'name': 'Optimal New Motherhub Location'\n",
    "                }\n",
    "            ],\n",
    "            'layout': {\n",
    "                'mapbox': {\n",
    "                    'style': \"open-street-map\",\n",
    "                    'center': {'lat': 12.97, 'lon': 77.59},  # Center coordinates of Bangalore\n",
    "                    'zoom': 10\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "])\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, port=8051)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
