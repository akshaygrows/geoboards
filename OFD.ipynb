{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajat/anaconda3/envs/gisenv/lib/python3.11/site-packages/paramiko/transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "from sshtunnel import SSHTunnelForwarder\n",
    "import psycopg2 as psy\n",
    "import pandas as pd\n",
    "from IPython.display import FileLink\n",
    "import geopandas as gpd\n",
    "import plotly.express as px\n",
    "from dash import Dash, dcc, html, Input, Output\n",
    "import paramiko\n",
    "from io import StringIO\n",
    "from shapely.geometry import MultiPoint, MultiPolygon\n",
    "from sklearn import preprocessing, cluster\n",
    "import scipy\n",
    "import scipy.cluster\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from shapely.ops import unary_union\n",
    "import calendar\n",
    "from datetime import datetime\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conn(SSH_required,key_path):   #for getting a connection as a result\n",
    "\n",
    "    db='datawarehouse'\n",
    "    DB_HOST='datawarehouse.cdgpvetprks3.ap-south-1.rds.amazonaws.com'\n",
    "    conn = []\n",
    "    if SSH_required == 'Yes':\n",
    "        SSH_HOST='ec2-15-206-161-154.ap-south-1.compute.amazonaws.com'\n",
    "        #LOCALHOST=\"0.0.0.0\"\n",
    "        ssh_tunnel= SSHTunnelForwarder(\n",
    "                (SSH_HOST, 22),\n",
    "                ssh_username=\"ec2-user\",\n",
    "                ssh_private_key= key_path,\n",
    "                ssh_private_key_password= \"\",\n",
    "                remote_bind_address=(DB_HOST, 5432),\n",
    "                local_bind_address=('127.0.0.1', 0)\n",
    "        )\n",
    "        print('Tunnel Started')\n",
    "        ssh_tunnel.start()\n",
    "        conn = psy.connect(\n",
    "            host=ssh_tunnel.local_bind_host,\n",
    "            port=ssh_tunnel.local_bind_port,\n",
    "            user='postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        print('Connection Made')\n",
    "        return conn\n",
    "    else:\n",
    "        conn = psy.connect(\n",
    "            host = DB_HOST,\n",
    "            port = 5432,\n",
    "            user = 'postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        print('Connection Made')\n",
    "        return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_sql(SSH_required, query,key_path):   #for getting a datafarame as a result\n",
    "\n",
    "    db='datawarehouse'\n",
    "    DB_HOST='datawarehouse.cdgpvetprks3.ap-south-1.rds.amazonaws.com'\n",
    "    conn = None\n",
    "    if SSH_required == 'Yes':\n",
    "        SSH_HOST='ec2-15-206-161-154.ap-south-1.compute.amazonaws.com'\n",
    "        #LOCALHOST=\"0.0.0.0\"\n",
    "        ssh_tunnel= SSHTunnelForwarder(\n",
    "                (SSH_HOST, 22),\n",
    "                ssh_username=\"ec2-user\",\n",
    "                ssh_private_key= key_path,\n",
    "                ssh_private_key_password= \"\",\n",
    "                remote_bind_address=(DB_HOST, 5432),\n",
    "                local_bind_address=('127.0.0.1', 0)\n",
    "        )\n",
    "        # ssh_tunnel._server_list[0].block_on_close = False\n",
    "        ssh_tunnel.start()\n",
    "        conn = psy.connect(\n",
    "            host=ssh_tunnel.local_bind_host,\n",
    "            port=ssh_tunnel.local_bind_port,\n",
    "            user='postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        df_results = pd.read_sql(query, conn)\n",
    "        conn.close()\n",
    "        ssh_tunnel.stop()\n",
    "        return df_results\n",
    "    else:\n",
    "        conn = psy.connect(\n",
    "            host = DB_HOST,\n",
    "            port = 5432,\n",
    "            user = 'postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        df_results = pd.read_sql(query, conn)\n",
    "        conn.close()\n",
    "        return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunnel Started\n",
      "Connection Made\n",
      "     shipping_pincode        ofd%\n",
      "0              110003   88.888889\n",
      "1              110005   97.029703\n",
      "2              110007   97.674419\n",
      "3              110008   96.992481\n",
      "4              110009   93.717277\n",
      "..                ...         ...\n",
      "421            560109  100.000000\n",
      "422            560110  100.000000\n",
      "423            560111  100.000000\n",
      "424            560114  100.000000\n",
      "425            800016  100.000000\n",
      "\n",
      "[426 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Usage with the actual path to the private key\n",
    "SSH_required = 'Yes'\n",
    "key_path = '/home/rajat/Downloads/tunnel-ssh .cer'\n",
    "query = \"\"\"with base as (    \n",
    "    select\n",
    "            shipping_pincode\n",
    "        ,   sum(ofd) as ofd\n",
    "        ,   sum(efd) as efd\n",
    "    from public.pincode_level_metrics\n",
    "    where 1=1\n",
    "    and datetime = date_trunc('day',now()+interval '5.5 hours') - interval '1 day'\n",
    "    and (efd is not null or efd != 0)\n",
    "    group by 1\n",
    ")\n",
    ",\n",
    "final as (\n",
    "    select\n",
    "        shipping_pincode\n",
    "    ,   coalesce(ofd::double precision/nullif(efd, 0), 0)*100 as \"ofd%\"\n",
    "    from base\n",
    "    order by 1\n",
    "    )\n",
    "    \n",
    "select * from final\"\"\"\n",
    "\n",
    "\n",
    "# Establish a connection\n",
    "conn = get_conn(SSH_required, key_path)\n",
    "\n",
    "# Retrieve data into a DataFrame\n",
    "df = get_df_from_sql(SSH_required, query, key_path)\n",
    "\n",
    "# Now you can perform further operations with the DataFrame 'df'\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading GeoJSON\n",
    "gdf_geojson = gpd.read_file(\"/home/rajat/GIS Blitznow/India_Pincodes/india_pincodes.shp\")\n",
    "\n",
    "# If the current CRS is geographic, re-project to UTM (EPSG:32644)\n",
    "if gdf_geojson.crs.is_geographic:\n",
    "    gdf_geojson = gdf_geojson.to_crs('EPSG:32644')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating centroids of pincodes\n",
    "gdf_geojson = gdf_geojson.to_crs(epsg=4326)\n",
    "\n",
    "gdf_geojson['latitude'] = gdf_geojson['geometry'].centroid.y\n",
    "gdf_geojson['longitude'] = gdf_geojson['geometry'].centroid.x\n",
    "\n",
    "# Ensure the pincode column datatype is consistent\n",
    "df['shipping_pincode'] = df['shipping_pincode'].astype(str)\n",
    "gdf_geojson['pincode'] = gdf_geojson['pincode'].astype(str)\n",
    "\n",
    "# Merge GeoDataFrame and DataFrame\n",
    "merged_gdf = gdf_geojson.merge(df, left_on='pincode', right_on='shipping_pincode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_gdf = merged_gdf[merged_gdf['district'] == 'Bangalore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8056/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7dcaf2094d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize Dash app\n",
    "app = Dash(__name__)\n",
    "\n",
    "# Get unique districts for the dropdown options and add 'All Districts' option\n",
    "districts = merged_gdf['district'].unique()\n",
    "district_options = [{'label': 'All Districts', 'value': 'All'}] + [{'label': district, 'value': district} for district in districts]\n",
    "\n",
    "# Define app layout\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Orders Delivered Yesterday by Pincode\", style={'text-align': 'center'}),\n",
    "    dcc.Dropdown(\n",
    "        id='district-dropdown',\n",
    "        options=district_options,\n",
    "        value='All',  # Default to 'All Districts'\n",
    "        style={'width': '50%'}\n",
    "    ),\n",
    "    dcc.Graph(id='map', figure={}),\n",
    "])\n",
    "\n",
    "# Callback to update the graph\n",
    "@app.callback(\n",
    "    Output(component_id='map', component_property='figure'),\n",
    "    Input(component_id='district-dropdown', component_property='value')\n",
    ")\n",
    "def update_graph(selected_district):\n",
    "    if selected_district == 'All':\n",
    "        filtered_gdf = merged_gdf\n",
    "    else:\n",
    "        filtered_gdf = merged_gdf[merged_gdf['district'] == selected_district]\n",
    "\n",
    "    fig = px.choropleth_mapbox(\n",
    "        filtered_gdf,\n",
    "        geojson=filtered_gdf.geometry.__geo_interface__,\n",
    "        locations=filtered_gdf.index,\n",
    "        color='ofd%',\n",
    "        hover_data=['shipping_pincode', 'ofd%'],\n",
    "        mapbox_style=\"carto-positron\",\n",
    "        center={\"lat\": filtered_gdf['latitude'].mean(), \"lon\": filtered_gdf['longitude'].mean()},\n",
    "        zoom=10,\n",
    "        opacity=0.9,\n",
    "        template='plotly_dark',\n",
    "        color_continuous_scale=\"RdYlGn\"\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, port=8056)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
