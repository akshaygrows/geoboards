{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36685103-4cc9-4596-ba5c-0bd9fec47dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sshtunnel import SSHTunnelForwarder\n",
    "import psycopg2 as psy\n",
    "import pandas as pd\n",
    "from IPython.display import FileLink\n",
    "import geopandas as gpd\n",
    "import plotly.express as px\n",
    "from dash import Dash, dcc, html, Input, Output\n",
    "import paramiko\n",
    "from io import StringIO\n",
    "from shapely.geometry import MultiPoint, MultiPolygon\n",
    "from sklearn import preprocessing, cluster\n",
    "import scipy\n",
    "import scipy.cluster\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from shapely.ops import unary_union\n",
    "import calendar\n",
    "from datetime import datetime\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f8a090c-ecae-4502-a7d2-7fdeba12bda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conn(SSH_required,key_path):   #for getting a connection as a result\n",
    "\n",
    "    db='datawarehouse'\n",
    "    DB_HOST='datawarehouse.cdgpvetprks3.ap-south-1.rds.amazonaws.com'\n",
    "    conn = []\n",
    "    if SSH_required == 'Yes':\n",
    "        SSH_HOST='ec2-15-206-161-154.ap-south-1.compute.amazonaws.com'\n",
    "        #LOCALHOST=\"0.0.0.0\"\n",
    "        ssh_tunnel= SSHTunnelForwarder(\n",
    "                (SSH_HOST, 22),\n",
    "                ssh_username=\"ec2-user\",\n",
    "                ssh_private_key= key_path,\n",
    "                ssh_private_key_password= \"\",\n",
    "                remote_bind_address=(DB_HOST, 5432),\n",
    "                local_bind_address=('127.0.0.1', 0)\n",
    "        )\n",
    "        print('Tunnel Started')\n",
    "        ssh_tunnel.start()\n",
    "        conn = psy.connect(\n",
    "            host=ssh_tunnel.local_bind_host,\n",
    "            port=ssh_tunnel.local_bind_port,\n",
    "            user='postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        print('Connection Made')\n",
    "        return conn\n",
    "    else:\n",
    "        conn = psy.connect(\n",
    "            host = DB_HOST,\n",
    "            port = 5432,\n",
    "            user = 'postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        print('Connection Made')\n",
    "        return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d5604fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_sql(SSH_required, query,key_path):   #for getting a datafarame as a result\n",
    "\n",
    "    db='datawarehouse'\n",
    "    DB_HOST='datawarehouse.cdgpvetprks3.ap-south-1.rds.amazonaws.com'\n",
    "    conn = None\n",
    "    if SSH_required == 'Yes':\n",
    "        SSH_HOST='ec2-15-206-161-154.ap-south-1.compute.amazonaws.com'\n",
    "        #LOCALHOST=\"0.0.0.0\"\n",
    "        ssh_tunnel= SSHTunnelForwarder(\n",
    "                (SSH_HOST, 22),\n",
    "                ssh_username=\"ec2-user\",\n",
    "                ssh_private_key= key_path,\n",
    "                ssh_private_key_password= \"\",\n",
    "                remote_bind_address=(DB_HOST, 5432),\n",
    "                local_bind_address=('127.0.0.1', 0)\n",
    "        )\n",
    "        # ssh_tunnel._server_list[0].block_on_close = False\n",
    "        ssh_tunnel.start()\n",
    "        conn = psy.connect(\n",
    "            host=ssh_tunnel.local_bind_host,\n",
    "            port=ssh_tunnel.local_bind_port,\n",
    "            user='postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        df_results = pd.read_sql(query, conn)\n",
    "        conn.close()\n",
    "        ssh_tunnel.stop()\n",
    "        return df_results\n",
    "    else:\n",
    "        conn = psy.connect(\n",
    "            host = DB_HOST,\n",
    "            port = 5432,\n",
    "            user = 'postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        df_results = pd.read_sql(query, conn)\n",
    "        conn.close()\n",
    "        return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a3759dd-1ae0-4a28-bbae-e3a403b8b0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunnel Started\n",
      "Connection Made\n",
      "                awb attribution   lost_date  shipment_value            awb  \\\n",
      "0      GS2063252782         Hub  2024-02-28          549.00   GS2063252782   \n",
      "1      GS1060449948       Rider  2024-02-26          597.00   GS1060449948   \n",
      "2      GS1216427309          FM  2024-02-08          199.00   GS1216427309   \n",
      "3      GS1041031256       Rider  2024-02-06          474.05   GS1041031256   \n",
      "4      GS1809946477       Rider  2024-02-06          565.00   GS1809946477   \n",
      "...             ...         ...         ...             ...            ...   \n",
      "2844  BZPPL00537523         Hub  2024-07-04         2558.00  BZPPL00537523   \n",
      "2845   GS1365432817         Hub  2024-04-08          782.00   GS1365432817   \n",
      "2846   GS1488111973       Rider  2024-05-03          302.00   GS1488111973   \n",
      "2847   GS1774425322         Hub  2024-06-24          202.00   GS1774425322   \n",
      "2848   GS1309786834       Rider  2024-02-06         2099.00   GS1309786834   \n",
      "\n",
      "      shipment_id                shop_order_number shipment_status  \\\n",
      "0         4354278                    #GI0012133158            Lost   \n",
      "1         4136914                       #WBN442545            Lost   \n",
      "2         4196943                    1707055099-04            Lost   \n",
      "3         4093489  MA-91020698521_SP9/2223/2523816            Lost   \n",
      "4         4097253                     BVL222914570            Lost   \n",
      "...           ...                              ...             ...   \n",
      "2844      6730457                    BZPPL00537523            Lost   \n",
      "2845      4870639      MA-91023647889_SP44-1334258            Lost   \n",
      "2846      5516458                        053414398            Lost   \n",
      "2847      6449685                    1718350595-99            Lost   \n",
      "2848      3815264                          1257208            Lost   \n",
      "\n",
      "     shipment_type shipping_zone  ...      dest_city_time  ideal_transit_time  \\\n",
      "0       Sur 1.0 kg         Metro  ...                 NaT                 NaT   \n",
      "1       Sur 1.0 kg     Intracity  ...                 NaT                 NaT   \n",
      "2       Sur 1.0 kg     Intracity  ...                 NaT                 NaT   \n",
      "3       Sur 1.0 kg     Intracity  ...                 NaT                 NaT   \n",
      "4       Sur 1.0 kg     Intracity  ...                 NaT                 NaT   \n",
      "...            ...           ...  ...                 ...                 ...   \n",
      "2844    Sur 1.0 kg   Within Zone  ... 2024-06-30 07:57:41 2024-06-30 08:00:00   \n",
      "2845    Sur 1.0 kg     Intracity  ... 2024-03-20 19:45:25 2024-03-21 00:00:00   \n",
      "2846    Sur 1.0 kg     Intracity  ... 2024-04-28 18:54:22 2024-04-29 00:00:00   \n",
      "2847    Sur 1.0 kg     Intracity  ... 2024-06-15 10:32:41 2024-06-16 00:00:00   \n",
      "2848    Sur 1.0 kg     Intracity  ... 2024-01-16 12:49:08 2024-01-13 00:00:00   \n",
      "\n",
      "       ideal_inscan_time cross_dock_in_scan_time cross_dock_out_scan_time  \\\n",
      "0                    NaT                     NaT                      NaT   \n",
      "1                    NaT                     NaT                      NaT   \n",
      "2                    NaT                     NaT                      NaT   \n",
      "3                    NaT                     NaT                      NaT   \n",
      "4                    NaT                     NaT                      NaT   \n",
      "...                  ...                     ...                      ...   \n",
      "2844 2024-06-30 11:00:00     2024-06-30 03:17:23      2024-06-30 05:12:53   \n",
      "2845 2024-03-22 00:00:00                     NaT                      NaT   \n",
      "2846 2024-04-30 00:00:00                     NaT                      NaT   \n",
      "2847 2024-06-17 00:00:00                     NaT                      NaT   \n",
      "2848 2024-01-14 00:00:00                     NaT                      NaT   \n",
      "\n",
      "     mother_hub_in_scan_time mother_hub_out_scan_time   lmds_in_scan_time  \\\n",
      "0                        NaT                      NaT                 NaT   \n",
      "1                        NaT                      NaT                 NaT   \n",
      "2                        NaT                      NaT                 NaT   \n",
      "3                        NaT                      NaT                 NaT   \n",
      "4                        NaT                      NaT                 NaT   \n",
      "...                      ...                      ...                 ...   \n",
      "2844     2024-06-30 07:57:41                      NaT 2024-06-30 07:57:42   \n",
      "2845                     NaT                      NaT                 NaT   \n",
      "2846     2024-04-28 18:54:22      2024-04-29 06:48:50 2024-04-29 08:37:41   \n",
      "2847     2024-06-15 10:32:41      2024-06-15 13:46:37 2024-06-15 15:21:37   \n",
      "2848                     NaT                      NaT                 NaT   \n",
      "\n",
      "           node_name sort_codes  \n",
      "0        DS HYD SRNG   HYD/SRNG  \n",
      "1         DS BOM KRL    BOM/KRL  \n",
      "2        DEL FRH GKP   NCR/EDGP  \n",
      "3     STNG-Franchise   BLR/STNG  \n",
      "4         DS DEL DWK   DEL/DWRK  \n",
      "...              ...        ...  \n",
      "2844     DS DEL NOID   NCR/NOID  \n",
      "2845     DS HYD MHDP   HYD/MHDP  \n",
      "2846     DS BLR BOMM   BLR/JPNR  \n",
      "2847     DS BOM SWRI   BOM/SWRI  \n",
      "2848     DS HYD TRNK   HYD/TRNK  \n",
      "\n",
      "[2849 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "# Usage with the actual path to the private key\n",
    "SSH_required = 'Yes'\n",
    "key_path = '/Users/rajatsansaniwal/Documents/tunnel-ssh .cer'\n",
    "query = \"\"\"select\n",
    "    l.awb\n",
    ",   l.attribution\n",
    ",   l.lost_date\n",
    ",   l.shipment_value\n",
    ",   o.*\n",
    ",   n.node_name\n",
    ",   sort_codes\n",
    "from public.lost_attribution as l\n",
    "left join public.ops_main as o on l.awb = o.awb\n",
    "left join application_db.node as n on trim(split_part(n.sort_codes,'/',2)) = trim(o.last_mile_hub)\n",
    "where shipping_partner = 'Hyperlocal' and created_date >= '2024-01-01'\"\"\"\n",
    "\n",
    "\n",
    "# Establish a connection\n",
    "conn = get_conn(SSH_required, key_path)\n",
    "\n",
    "# Retrieve data into a DataFrame\n",
    "df = get_df_from_sql(SSH_required, query, key_path)\n",
    "\n",
    "# Now you can perform further operations with the DataFrame 'df'\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b515d13-7e40-43c6-bc14-c06275ebc228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading GeoJSON\n",
    "gdf_geojson = gpd.read_file(\"/Users/rajatsansaniwal/git_geoboards/geoboards/India_Pincodes/india_pincodes.shp\")\n",
    "\n",
    "\n",
    "# If the current CRS is geographic, re-project to UTM (EPSG:32644)\n",
    "if gdf_geojson.crs.is_geographic:\n",
    "    gdf_geojson = gdf_geojson.to_crs('EPSG:32644')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a7dccfc-a9c3-4897-adfa-8d737b00ead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating centroids of pincodes\n",
    "gdf_geojson = gdf_geojson.to_crs(epsg=4326)\n",
    "\n",
    "gdf_geojson['latitude'] = gdf_geojson['geometry'].centroid.y\n",
    "gdf_geojson['longitude'] = gdf_geojson['geometry'].centroid.x\n",
    "\n",
    "# Ensure the pincode column datatype is consistent\n",
    "df['shipping_pincode'] = df['shipping_pincode'].astype(str)\n",
    "gdf_geojson['pincode'] = gdf_geojson['pincode'].astype(str)\n",
    "\n",
    "# Merge GeoDataFrame and DataFrame\n",
    "merged_gdf = gdf_geojson.merge(df, left_on='pincode', right_on='shipping_pincode')\n",
    "merged_gdf['last_scan_time'] = pd.to_datetime(merged_gdf['last_scan_time'])\n",
    "merged_gdf['last_scan_week'] = merged_gdf['last_scan_time'].dt.to_period('W').dt.week\n",
    "\n",
    "# Generate a list of unique week start dates\n",
    "week_start_dates = merged_gdf['last_scan_time'].dt.to_period('W').dt.start_time.unique()\n",
    "\n",
    "# Sort the week start dates in ascending order\n",
    "week_start_dates = sorted(week_start_dates)\n",
    "\n",
    "# Generate marks with week numbers as keys and corresponding start dates as labels\n",
    "marks = {str(week): {'label': str(date.date())} for week, date in enumerate(week_start_dates, start=1)}\n",
    "\n",
    "min_week = min(int(week) for week in marks.keys())\n",
    "max_week = max(int(week) for week in marks.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0223428-738e-459b-b400-bdd70cec5241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8055/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x144dcfc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link to access Dash app externally:\n",
      "http://localhost:8055/\n"
     ]
    }
   ],
   "source": [
    "# Initialize Dash app\n",
    "app = Dash(__name__)\n",
    "\n",
    "# Define app layout\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Orders lost on Shipping Pincode\", style={'text-align': 'center'}),\n",
    "    dcc.Input(\n",
    "        id='search_shippingcity',\n",
    "        type='text',\n",
    "        placeholder='Search Shipping City...',\n",
    "        value='Bangalore',\n",
    "        style={'width': \"40%\"}\n",
    "    ),\n",
    "    html.Div(style={'height': '20px'}),\n",
    "    dcc.RangeSlider(\n",
    "        id='week-slider',\n",
    "        min=min_week,\n",
    "        max=max_week,\n",
    "        marks=marks,\n",
    "        value=[min_week + 1, min_week+2] \n",
    "    ),\n",
    "    html.Div(style={'height': '20px'}),\n",
    "    dcc.Dropdown(\n",
    "        id='attribution-dropdown',\n",
    "        options=[\n",
    "            {'label': 'Rider', 'value': 'Rider'},\n",
    "            {'label': 'Hub', 'value': 'Hub'}\n",
    "        ],\n",
    "        value=['Hub', 'Rider'],\n",
    "        multi=True  # Allow multiple selection\n",
    "    ),\n",
    "    html.Div(style={'height': '20px'}),\n",
    "    html.Div(id='output_container_city', children=[]),\n",
    "    html.Div(id='output_container_month', children=[]),\n",
    "    html.Br(),\n",
    "    html.Div([\n",
    "        dcc.Graph(id='map', figure={}),\n",
    "    ])\n",
    "])\n",
    "\n",
    "# Callback to update the graph\n",
    "@app.callback(\n",
    "    [Output(component_id='output_container_city', component_property='children'),\n",
    "     Output(component_id='map', component_property='figure')],\n",
    "    [Input(component_id='search_shippingcity', component_property='value'),\n",
    "     Input(component_id='week-slider', component_property='value'),\n",
    "     Input(component_id='attribution-dropdown', component_property='value')]\n",
    ")\n",
    "def update_graph(city_slctd, selected_weeks, selected_attributions, min_week=min_week, max_week=max_week, marks=marks):\n",
    "    if not city_slctd or city_slctd not in merged_gdf['shipping_city'].unique():\n",
    "        return \"\", {}\n",
    "    output_container_city = \"Results are shown for the Shipping City: {}\".format(city_slctd)\n",
    "    \n",
    "    # Convert the selected weeks integers to strings\n",
    "    selected_min_date = str(selected_weeks[0])\n",
    "    selected_max_date = str(selected_weeks[1])\n",
    "    \n",
    "    # Filter the data for the selected city, selected weeks, and selected attributions\n",
    "    dff = merged_gdf[(merged_gdf[\"shipping_city\"] == city_slctd) & \n",
    "                     (merged_gdf[\"last_scan_week\"].astype(str) >= selected_min_date) &\n",
    "                     (merged_gdf[\"last_scan_week\"].astype(str) < selected_max_date) &\n",
    "                     (merged_gdf['attribution'].isin(selected_attributions))]\n",
    "    \n",
    "    grouped_data = dff.groupby(['shipping_pincode', 'officename', 'geometry']).size().reset_index(name='lost_orders')\n",
    "    grouped_data = gpd.GeoDataFrame(grouped_data, geometry='geometry')\n",
    "    \n",
    "    # Generate centroid\n",
    "    centroid = grouped_data.geometry.centroid\n",
    "    centroid_wgs84 = centroid.to_crs(epsg=4326)\n",
    "    grouped_data['geometry'] = grouped_data['geometry'].simplify(tolerance=0.001)\n",
    "    \n",
    "    fig = px.choropleth_mapbox(\n",
    "        grouped_data,  # Use filtered data from merged_gdf\n",
    "        geojson=grouped_data.geometry,  # Pass geometry from filtered data\n",
    "        locations=grouped_data.index,  # Use index from filtered data\n",
    "        color='lost_orders',\n",
    "        hover_data=['shipping_pincode', 'officename', 'lost_orders'],\n",
    "        mapbox_style=\"carto-positron\",\n",
    "        center={\"lat\": centroid_wgs84.y.mean(), \"lon\": centroid_wgs84.x.mean()},\n",
    "        zoom=8.5,\n",
    "        opacity=0.9,\n",
    "        template='plotly_dark',\n",
    "        color_continuous_scale=\"RdYlGn_r\"\n",
    "    )\n",
    "    return output_container_city, fig\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    port = 8055\n",
    "    app.run(debug=True, port=port, mode='external')\n",
    "    dash_app_link = f\"http://localhost:{port}/\"\n",
    "    print(\"Link to access Dash app externally:\")\n",
    "    print(dash_app_link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0de3809-c381-4ebd-a914-88b2eb092c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
