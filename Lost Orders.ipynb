{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36685103-4cc9-4596-ba5c-0bd9fec47dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajat/anaconda3/envs/gisenv/lib/python3.11/site-packages/paramiko/transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "from sshtunnel import SSHTunnelForwarder\n",
    "import psycopg2 as psy\n",
    "import pandas as pd\n",
    "from IPython.display import FileLink\n",
    "import geopandas as gpd\n",
    "import plotly.express as px\n",
    "from dash import Dash, dcc, html, Input, Output\n",
    "import paramiko\n",
    "from io import StringIO\n",
    "from shapely.geometry import MultiPoint, MultiPolygon\n",
    "from sklearn import preprocessing, cluster\n",
    "import scipy\n",
    "import scipy.cluster\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from shapely.ops import unary_union\n",
    "import calendar\n",
    "from datetime import datetime\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f8a090c-ecae-4502-a7d2-7fdeba12bda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conn(SSH_required,key_path):   #for getting a connection as a result\n",
    "\n",
    "    db='datawarehouse'\n",
    "    DB_HOST='datawarehouse.cdgpvetprks3.ap-south-1.rds.amazonaws.com'\n",
    "    conn = []\n",
    "    if SSH_required == 'Yes':\n",
    "        SSH_HOST='ec2-15-206-161-154.ap-south-1.compute.amazonaws.com'\n",
    "        #LOCALHOST=\"0.0.0.0\"\n",
    "        ssh_tunnel= SSHTunnelForwarder(\n",
    "                (SSH_HOST, 22),\n",
    "                ssh_username=\"ec2-user\",\n",
    "                ssh_private_key= key_path,\n",
    "                ssh_private_key_password= \"\",\n",
    "                remote_bind_address=(DB_HOST, 5432),\n",
    "                local_bind_address=('127.0.0.1', 0)\n",
    "        )\n",
    "        print('Tunnel Started')\n",
    "        ssh_tunnel.start()\n",
    "        conn = psy.connect(\n",
    "            host=ssh_tunnel.local_bind_host,\n",
    "            port=ssh_tunnel.local_bind_port,\n",
    "            user='postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        print('Connection Made')\n",
    "        return conn\n",
    "    else:\n",
    "        conn = psy.connect(\n",
    "            host = DB_HOST,\n",
    "            port = 5432,\n",
    "            user = 'postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        print('Connection Made')\n",
    "        return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d5604fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_sql(SSH_required, query,key_path):   #for getting a datafarame as a result\n",
    "\n",
    "    db='datawarehouse'\n",
    "    DB_HOST='datawarehouse.cdgpvetprks3.ap-south-1.rds.amazonaws.com'\n",
    "    conn = None\n",
    "    if SSH_required == 'Yes':\n",
    "        SSH_HOST='ec2-15-206-161-154.ap-south-1.compute.amazonaws.com'\n",
    "        #LOCALHOST=\"0.0.0.0\"\n",
    "        ssh_tunnel= SSHTunnelForwarder(\n",
    "                (SSH_HOST, 22),\n",
    "                ssh_username=\"ec2-user\",\n",
    "                ssh_private_key= key_path,\n",
    "                ssh_private_key_password= \"\",\n",
    "                remote_bind_address=(DB_HOST, 5432),\n",
    "                local_bind_address=('127.0.0.1', 0)\n",
    "        )\n",
    "        # ssh_tunnel._server_list[0].block_on_close = False\n",
    "        ssh_tunnel.start()\n",
    "        conn = psy.connect(\n",
    "            host=ssh_tunnel.local_bind_host,\n",
    "            port=ssh_tunnel.local_bind_port,\n",
    "            user='postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        df_results = pd.read_sql(query, conn)\n",
    "        conn.close()\n",
    "        ssh_tunnel.stop()\n",
    "        return df_results\n",
    "    else:\n",
    "        conn = psy.connect(\n",
    "            host = DB_HOST,\n",
    "            port = 5432,\n",
    "            user = 'postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        df_results = pd.read_sql(query, conn)\n",
    "        conn.close()\n",
    "        return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a3759dd-1ae0-4a28-bbae-e3a403b8b0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunnel Started\n",
      "Connection Made\n",
      "                awb attribution   lost_date  shipment_value            awb  \\\n",
      "0      GS1843640610       Rider  2024-02-01           698.0   GS1843640610   \n",
      "1      GS1752437944          FM  2024-02-01           549.0   GS1752437944   \n",
      "2      GS2140144762       Rider  2024-02-01           183.0   GS2140144762   \n",
      "3      GS1832490284       Rider  2024-02-01          1449.0   GS1832490284   \n",
      "4      GS1641639613         Hub  2024-02-01           463.0   GS1641639613   \n",
      "...             ...         ...         ...             ...            ...   \n",
      "1872  BZPPL00342143         Hub  2024-05-21          1851.0  BZPPL00342143   \n",
      "1873  BZPPL00339109         Hub  2024-05-21          1847.0  BZPPL00339109   \n",
      "1874  BZPPL00341501         Hub  2024-05-21          3417.0  BZPPL00341501   \n",
      "1875  BZPPL00339698         Hub  2024-05-21           638.0  BZPPL00339698   \n",
      "1876  BZPPL00338307         Hub  2024-05-21          1326.0  BZPPL00338307   \n",
      "\n",
      "      shipment_id          shop_order_number shipment_status shipment_type  \\\n",
      "0         4095710  MA-91020696547_HC10335602            Lost    Sur 1.0 kg   \n",
      "1         3933451               BVL222899645            Lost    Sur 1.0 kg   \n",
      "2         3859221        FL20240114309977285            Lost    Sur 1.0 kg   \n",
      "3         3963082               #RCOM1223503            Lost    Sur 1.0 kg   \n",
      "4         3971873              1705931186-35            Lost    Sur 1.0 kg   \n",
      "...           ...                        ...             ...           ...   \n",
      "1872      5823718              BZPPL00342143            Lost    Sur 1.0 kg   \n",
      "1873      5828463              BZPPL00339109            Lost    Sur 1.0 kg   \n",
      "1874      5836355              BZPPL00341501            Lost    Sur 1.0 kg   \n",
      "1875      5838407              BZPPL00339698            Lost    Sur 1.0 kg   \n",
      "1876      5838583              BZPPL00338307            Lost    Sur 1.0 kg   \n",
      "\n",
      "     shipping_zone  ...      lost_mark_time    hub_in_scan_time  \\\n",
      "0        Intracity  ...                 NaT                 NaT   \n",
      "1        Intracity  ...                 NaT                 NaT   \n",
      "2        Intracity  ...                 NaT                 NaT   \n",
      "3        Intracity  ...                 NaT                 NaT   \n",
      "4        Intracity  ...                 NaT                 NaT   \n",
      "...            ...  ...                 ...                 ...   \n",
      "1872   Within Zone  ... 2024-05-21 15:52:39 2024-05-15 04:05:04   \n",
      "1873   Within Zone  ... 2024-05-21 15:50:10 2024-05-15 04:06:19   \n",
      "1874   Within Zone  ... 2024-05-21 15:50:25 2024-05-15 04:03:41   \n",
      "1875   Within Zone  ... 2024-05-21 15:50:18 2024-05-15 04:04:32   \n",
      "1876   Within Zone  ... 2024-05-21 15:50:32 2024-05-15 04:01:07   \n",
      "\n",
      "         cfc_pickup_time addtobag_time in_transit_time dest_city_time  \\\n",
      "0                    NaT           NaT             NaT            NaT   \n",
      "1                    NaT           NaT             NaT            NaT   \n",
      "2                    NaT           NaT             NaT            NaT   \n",
      "3                    NaT           NaT             NaT            NaT   \n",
      "4                    NaT           NaT             NaT            NaT   \n",
      "...                  ...           ...             ...            ...   \n",
      "1872 2024-05-15 01:47:12           NaT             NaT            NaT   \n",
      "1873 2024-05-15 01:48:10           NaT             NaT            NaT   \n",
      "1874 2024-05-15 01:56:12           NaT             NaT            NaT   \n",
      "1875 2024-05-15 02:32:58           NaT             NaT            NaT   \n",
      "1876 2024-05-15 02:45:16           NaT             NaT            NaT   \n",
      "\n",
      "     ideal_transit_time ideal_inscan_time       node_name sort_codes  \n",
      "0                   NaT               NaT      DS BOM KRL    BOM/KRL  \n",
      "1                   NaT               NaT     DS HYD SRNG   HYD/SRNG  \n",
      "2                   NaT               NaT     DS BLR BOMM   BLR/JPNR  \n",
      "3                   NaT               NaT     DS BLR BOMM   BLR/JPNR  \n",
      "4                   NaT               NaT      DS DEL DWK   DEL/DWRK  \n",
      "...                 ...               ...             ...        ...  \n",
      "1872         2024-05-16        2024-05-17  FABD-Franchise   NCR/FABD  \n",
      "1873         2024-05-16        2024-05-17  FABD-Franchise   NCR/FABD  \n",
      "1874         2024-05-16        2024-05-17  FABD-Franchise   NCR/FABD  \n",
      "1875         2024-05-16        2024-05-17  FABD-Franchise   NCR/FABD  \n",
      "1876         2024-05-16        2024-05-17  FABD-Franchise   NCR/FABD  \n",
      "\n",
      "[1877 rows x 67 columns]\n"
     ]
    }
   ],
   "source": [
    "# Usage with the actual path to the private key\n",
    "SSH_required = 'Yes'\n",
    "key_path = '/home/rajat/Downloads/tunnel-ssh .cer'\n",
    "query = \"\"\"select\n",
    "    l.awb\n",
    ",   l.attribution\n",
    ",   l.lost_date\n",
    ",   l.shipment_value\n",
    ",   o.*\n",
    ",   n.node_name\n",
    ",   sort_codes\n",
    "from public.lost_attribution as l\n",
    "left join public.ops_main as o on l.awb = o.awb\n",
    "left join application_db.node as n on trim(split_part(n.sort_codes,'/',2)) = trim(o.last_mile_hub)\n",
    "where shipping_partner = 'Hyperlocal' and created_date >= '2024-01-01'\"\"\"\n",
    "\n",
    "\n",
    "# Establish a connection\n",
    "conn = get_conn(SSH_required, key_path)\n",
    "\n",
    "# Retrieve data into a DataFrame\n",
    "df = get_df_from_sql(SSH_required, query, key_path)\n",
    "\n",
    "# Now you can perform further operations with the DataFrame 'df'\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b515d13-7e40-43c6-bc14-c06275ebc228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading GeoJSON\n",
    "gdf_geojson = gpd.read_file(\"/home/rajat/GIS Blitznow/India_Pincodes/india_pincodes.shp\")\n",
    "\n",
    "# If the current CRS is geographic, re-project to UTM (EPSG:32644)\n",
    "if gdf_geojson.crs.is_geographic:\n",
    "    gdf_geojson = gdf_geojson.to_crs('EPSG:32644')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a7dccfc-a9c3-4897-adfa-8d737b00ead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating centroids of pincodes\n",
    "gdf_geojson = gdf_geojson.to_crs(epsg=4326)\n",
    "\n",
    "gdf_geojson['latitude'] = gdf_geojson['geometry'].centroid.y\n",
    "gdf_geojson['longitude'] = gdf_geojson['geometry'].centroid.x\n",
    "\n",
    "# Ensure the pincode column datatype is consistent\n",
    "df['shipping_pincode'] = df['shipping_pincode'].astype(str)\n",
    "gdf_geojson['pincode'] = gdf_geojson['pincode'].astype(str)\n",
    "\n",
    "# Merge GeoDataFrame and DataFrame\n",
    "merged_gdf = gdf_geojson.merge(df, left_on='pincode', right_on='shipping_pincode')\n",
    "merged_gdf['last_scan_time'] = pd.to_datetime(merged_gdf['last_scan_time'])\n",
    "merged_gdf['last_scan_week'] = merged_gdf['last_scan_time'].dt.to_period('W').dt.week\n",
    "\n",
    "# Generate a list of unique week start dates\n",
    "week_start_dates = merged_gdf['last_scan_time'].dt.to_period('W').dt.start_time.unique()\n",
    "\n",
    "# Sort the week start dates in ascending order\n",
    "week_start_dates = sorted(week_start_dates)\n",
    "\n",
    "# Generate marks with week numbers as keys and corresponding start dates as labels\n",
    "marks = {str(week): {'label': str(date.date())} for week, date in enumerate(week_start_dates, start=1)}\n",
    "\n",
    "min_week = min(int(week) for week in marks.keys())\n",
    "max_week = max(int(week) for week in marks.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0223428-738e-459b-b400-bdd70cec5241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8055/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7154441f80d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link to access Dash app externally:\n",
      "http://localhost:8055/\n"
     ]
    }
   ],
   "source": [
    "# Initialize Dash app\n",
    "app = Dash(__name__)\n",
    "\n",
    "# Define app layout\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Orders lost on Shipping Pincode\", style={'text-align': 'center'}),\n",
    "    dcc.Input(\n",
    "        id='search_shippingcity',\n",
    "        type='text',\n",
    "        placeholder='Search Shipping City...',\n",
    "        value='Bangalore',\n",
    "        style={'width': \"40%\"}\n",
    "    ),\n",
    "    html.Div(style={'height': '20px'}),\n",
    "    dcc.RangeSlider(\n",
    "        id='week-slider',\n",
    "        min=min_week,\n",
    "        max=max_week,\n",
    "        marks=marks,\n",
    "        value=[min_week + 1, min_week+2] \n",
    "    ),\n",
    "    html.Div(style={'height': '20px'}),\n",
    "    dcc.Dropdown(\n",
    "        id='attribution-dropdown',\n",
    "        options=[\n",
    "            {'label': 'Rider', 'value': 'Rider'},\n",
    "            {'label': 'Hub', 'value': 'Hub'}\n",
    "        ],\n",
    "        value=['Hub', 'Rider'],\n",
    "        multi=True  # Allow multiple selection\n",
    "    ),\n",
    "    html.Div(style={'height': '20px'}),\n",
    "    html.Div(id='output_container_city', children=[]),\n",
    "    html.Div(id='output_container_month', children=[]),\n",
    "    html.Br(),\n",
    "    html.Div([\n",
    "        dcc.Graph(id='map', figure={}),\n",
    "    ])\n",
    "])\n",
    "\n",
    "# Callback to update the graph\n",
    "@app.callback(\n",
    "    [Output(component_id='output_container_city', component_property='children'),\n",
    "     Output(component_id='map', component_property='figure')],\n",
    "    [Input(component_id='search_shippingcity', component_property='value'),\n",
    "     Input(component_id='week-slider', component_property='value'),\n",
    "     Input(component_id='attribution-dropdown', component_property='value')]\n",
    ")\n",
    "def update_graph(city_slctd, selected_weeks, selected_attributions, min_week=min_week, max_week=max_week, marks=marks):\n",
    "    if not city_slctd or city_slctd not in merged_gdf['shipping_city'].unique():\n",
    "        return \"\", {}\n",
    "    output_container_city = \"Results are shown for the Shipping City: {}\".format(city_slctd)\n",
    "    \n",
    "    # Convert the selected weeks integers to strings\n",
    "    selected_min_date = str(selected_weeks[0])\n",
    "    selected_max_date = str(selected_weeks[1])\n",
    "    \n",
    "    # Filter the data for the selected city, selected weeks, and selected attributions\n",
    "    dff = merged_gdf[(merged_gdf[\"shipping_city\"] == city_slctd) & \n",
    "                     (merged_gdf[\"last_scan_week\"].astype(str) >= selected_min_date) &\n",
    "                     (merged_gdf[\"last_scan_week\"].astype(str) < selected_max_date) &\n",
    "                     (merged_gdf['attribution'].isin(selected_attributions))]\n",
    "    \n",
    "    grouped_data = dff.groupby(['shipping_pincode', 'officename', 'geometry']).size().reset_index(name='lost_orders')\n",
    "    grouped_data = gpd.GeoDataFrame(grouped_data, geometry='geometry')\n",
    "    \n",
    "    # Generate centroid\n",
    "    centroid = grouped_data.geometry.centroid\n",
    "    centroid_wgs84 = centroid.to_crs(epsg=4326)\n",
    "    grouped_data['geometry'] = grouped_data['geometry'].simplify(tolerance=0.001)\n",
    "    \n",
    "    fig = px.choropleth_mapbox(\n",
    "        grouped_data,  # Use filtered data from merged_gdf\n",
    "        geojson=grouped_data.geometry,  # Pass geometry from filtered data\n",
    "        locations=grouped_data.index,  # Use index from filtered data\n",
    "        color='lost_orders',\n",
    "        hover_data=['shipping_pincode', 'officename', 'lost_orders'],\n",
    "        mapbox_style=\"carto-positron\",\n",
    "        center={\"lat\": centroid_wgs84.y.mean(), \"lon\": centroid_wgs84.x.mean()},\n",
    "        zoom=8.5,\n",
    "        opacity=0.9,\n",
    "        template='plotly_dark',\n",
    "        color_continuous_scale=\"RdYlGn_r\"\n",
    "    )\n",
    "    return output_container_city, fig\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    port = 8055\n",
    "    app.run(debug=True, port=port, mode='external')\n",
    "    dash_app_link = f\"http://localhost:{port}/\"\n",
    "    print(\"Link to access Dash app externally:\")\n",
    "    print(dash_app_link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0de3809-c381-4ebd-a914-88b2eb092c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
