{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "import psycopg2 as psy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conn(SSH_required,key_path):   #for getting a connection as a result\n",
    "\n",
    "    db='datawarehouse'\n",
    "    DB_HOST='datawarehouse.cdgpvetprks3.ap-south-1.rds.amazonaws.com'\n",
    "    conn = []\n",
    "    if SSH_required == 'Yes':\n",
    "        SSH_HOST='ec2-15-206-161-154.ap-south-1.compute.amazonaws.com'\n",
    "        #LOCALHOST=\"0.0.0.0\"\n",
    "        ssh_tunnel= SSHTunnelForwarder(\n",
    "                (SSH_HOST, 22),\n",
    "                ssh_username=\"ec2-user\",\n",
    "                ssh_private_key= key_path,\n",
    "                ssh_private_key_password= \"\",\n",
    "                remote_bind_address=(DB_HOST, 5432),\n",
    "                local_bind_address=('127.0.0.1', 0)\n",
    "        )\n",
    "        print('Tunnel Started')\n",
    "        ssh_tunnel.start()\n",
    "        conn = psy.connect(\n",
    "            host=ssh_tunnel.local_bind_host,\n",
    "            port=ssh_tunnel.local_bind_port,\n",
    "            user='postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        print('Connection Made')\n",
    "        return conn\n",
    "    else:\n",
    "        conn = psy.connect(\n",
    "            host = DB_HOST,\n",
    "            port = 5432,\n",
    "            user = 'postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        print('Connection Made')\n",
    "        return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_sql(SSH_required, query,key_path):   #for getting a datafarame as a result\n",
    "\n",
    "    db='datawarehouse'\n",
    "    DB_HOST='datawarehouse.cdgpvetprks3.ap-south-1.rds.amazonaws.com'\n",
    "    conn = None\n",
    "    if SSH_required == 'Yes':\n",
    "        SSH_HOST='ec2-15-206-161-154.ap-south-1.compute.amazonaws.com'\n",
    "        #LOCALHOST=\"0.0.0.0\"\n",
    "        ssh_tunnel= SSHTunnelForwarder(\n",
    "                (SSH_HOST, 22),\n",
    "                ssh_username=\"ec2-user\",\n",
    "                ssh_private_key= key_path,\n",
    "                ssh_private_key_password= \"\",\n",
    "                remote_bind_address=(DB_HOST, 5432),\n",
    "                local_bind_address=('127.0.0.1', 0)\n",
    "        )\n",
    "        # ssh_tunnel._server_list[0].block_on_close = False\n",
    "        ssh_tunnel.start()\n",
    "        conn = psy.connect(\n",
    "            host=ssh_tunnel.local_bind_host,\n",
    "            port=ssh_tunnel.local_bind_port,\n",
    "            user='postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        df_results = pd.read_sql(query, conn)\n",
    "        conn.close()\n",
    "        ssh_tunnel.stop()\n",
    "        return df_results\n",
    "    else:\n",
    "        conn = psy.connect(\n",
    "            host = DB_HOST,\n",
    "            port = 5432,\n",
    "            user = 'postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        df_results = pd.read_sql(query, conn)\n",
    "        conn.close()\n",
    "        return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunnel Started\n",
      "Connection Made\n",
      "       warehouse_id               created_date           awb\n",
      "0                83 2024-07-07 08:07:29.551418  GS1362278349\n",
      "1                83 2024-07-07 08:10:26.063166  GS1054164984\n",
      "2                83 2024-07-07 08:19:34.502561  GS1331160028\n",
      "3                83 2024-07-07 08:25:34.501822  GS1961716865\n",
      "4                83 2024-07-07 08:34:30.164179  GS1301848766\n",
      "...             ...                        ...           ...\n",
      "40580          2147 2024-07-08 15:45:33.673427  GS1176585047\n",
      "40581          2151 2024-07-07 10:39:50.042359  GS1263341845\n",
      "40582          2151 2024-07-07 17:10:11.244005  GS1593016996\n",
      "40583          2151 2024-07-08 12:39:30.286308  GS1044316150\n",
      "40584          2151 2024-07-08 16:54:51.623534  GS1255804329\n",
      "\n",
      "[40585 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Usage with the actual path to the private key\n",
    "SSH_required = 'Yes'\n",
    "key_path = '/Users/rajatsansaniwal/Documents/tunnel-ssh .cer'\n",
    "query = \"\"\"with ops_main as (\n",
    "    select\n",
    "        awb\n",
    "    ,   created_date\n",
    "    from public.ops_main\n",
    "    where 1=1\n",
    "    and shipping_partner = 'Hyperlocal'\n",
    "    and date_trunc('day', created_date) >= date_trunc('day', now() + interval'5.5 hours' - interval'1 day')\n",
    ")\n",
    ",\n",
    "shipment_order_details as (\n",
    "    select\n",
    "        awb\n",
    "    ,   warehouse_id\n",
    "    from public.shipment_order_details\n",
    ")\n",
    ",\n",
    "base as (\n",
    "    select\n",
    "        s.warehouse_id\n",
    "    ,   o.created_date\n",
    "    ,   o.awb\n",
    "    from ops_main o\n",
    "    left join shipment_order_details s on o.awb = s.awb\n",
    "    order by 1, 2\n",
    ")\n",
    "\n",
    "select * from base\"\"\"\n",
    "\n",
    "# Establish a connection\n",
    "conn = get_conn(SSH_required, key_path)\n",
    "\n",
    "# Retrieve data into a DataFrame\n",
    "df = get_df_from_sql(SSH_required, query, key_path)\n",
    "\n",
    "# Now you can perform further operations with the DataFrame 'df'\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['created_date'] = pd.to_datetime(df['created_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'pickup_slots.xlsx'\n",
    "results_df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     warehouse_id   pickup_start_time     pickup_end_time  slot_duration  \\\n",
      "0              83 2024-07-06 16:49:33 2024-07-06 16:55:17              6   \n",
      "1             314 2024-07-06 01:40:19 2024-07-06 02:06:12             26   \n",
      "2             314 2024-07-06 15:42:51 2024-07-06 16:06:08             24   \n",
      "3             314 2024-07-06 17:37:28 2024-07-06 17:45:11              8   \n",
      "4             327 2024-07-06 18:49:49 2024-07-06 18:50:15              1   \n",
      "..            ...                 ...                 ...            ...   \n",
      "214          2142 2024-07-06 17:53:20 2024-07-06 17:53:58              1   \n",
      "215          2143 2024-07-06 18:54:56 2024-07-06 19:07:06             13   \n",
      "216          2144 2024-07-06 18:54:05 2024-07-06 19:07:28             14   \n",
      "217          2147 2024-07-06 12:23:09 2024-07-06 12:25:42              3   \n",
      "218          2151 2024-07-06 16:46:59 2024-07-06 16:47:04              1   \n",
      "\n",
      "     gap_to_next  load  actual_load  expected_load  \n",
      "0            NaN    47           47              0  \n",
      "1          817.0     2            2              0  \n",
      "2           92.0   128          128              0  \n",
      "3            NaN    89           89              0  \n",
      "4            NaN     6            6              0  \n",
      "..           ...   ...          ...            ...  \n",
      "214          NaN     3            3              0  \n",
      "215          NaN    38           38              0  \n",
      "216          NaN   126          126              0  \n",
      "217          NaN    12           12              0  \n",
      "218          NaN     2            2              0  \n",
      "\n",
      "[219 rows x 8 columns]\n",
      "DataFrame saved to expected_load.xlsx\n"
     ]
    }
   ],
   "source": [
    "expected_loads = []\n",
    "\n",
    "for warehouse, slot in results_df.groupby('warehouse_id'):\n",
    "    # slot = slot.reset_index(drop=True)\n",
    "\n",
    "    for index, row in slot.iterrows():\n",
    "        warehouse_id = row['warehouse_id']\n",
    "        slot_start_time = row['pickup_start_time']\n",
    "        slot_end_time = row['pickup_end_time']\n",
    "        \n",
    "        # Find the end time of the previous slot (if available)\n",
    "        if index > 0:\n",
    "            prev_slot_start_time = results_df.loc[index - 1, 'pickup_start_time']\n",
    "        else:\n",
    "            prev_slot_start_time = None\n",
    "        \n",
    "        # Filter df for current warehouse_id and pickups between previous slot's end time and current slot's start time\n",
    "        if prev_slot_start_time:\n",
    "            filtered_df = df[(df['warehouse_id'] == warehouse_id) & \n",
    "                             (df['created_date'] >= prev_slot_start_time) & \n",
    "                             (df['created_date'] < slot_start_time)]\n",
    "        else:\n",
    "            filtered_df = df[(df['warehouse_id'] == warehouse_id) & \n",
    "                             (df['created_date'] < slot_start_time)]\n",
    "\n",
    "        # Count the number of awbs within the slot time range\n",
    "        expected_load = len(filtered_df)\n",
    "        \n",
    "        # Append the expected load count to the list\n",
    "        expected_loads.append(expected_load)\n",
    "\n",
    "# Add the expected_loads list as a new column to results_df\n",
    "results_df['expected_load'] = expected_loads\n",
    "\n",
    "# Display the updated results_df with expected load column\n",
    "print(results_df)\n",
    "\n",
    "# Save DataFrame to Excel\n",
    "excel_file = 'expected_load.xlsx'\n",
    "results_df.to_excel(excel_file, index=False)\n",
    "\n",
    "print(f\"DataFrame saved to {excel_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
