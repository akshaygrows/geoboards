{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "import psycopg2 as psy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conn(SSH_required,key_path):   #for getting a connection as a result\n",
    "\n",
    "    db='datawarehouse'\n",
    "    DB_HOST='datawarehouse.cdgpvetprks3.ap-south-1.rds.amazonaws.com'\n",
    "    conn = []\n",
    "    if SSH_required == 'Yes':\n",
    "        SSH_HOST='ec2-15-206-161-154.ap-south-1.compute.amazonaws.com'\n",
    "        #LOCALHOST=\"0.0.0.0\"\n",
    "        ssh_tunnel= SSHTunnelForwarder(\n",
    "                (SSH_HOST, 22),\n",
    "                ssh_username=\"ec2-user\",\n",
    "                ssh_private_key= key_path,\n",
    "                ssh_private_key_password= \"\",\n",
    "                remote_bind_address=(DB_HOST, 5432),\n",
    "                local_bind_address=('127.0.0.1', 0)\n",
    "        )\n",
    "        print('Tunnel Started')\n",
    "        ssh_tunnel.start()\n",
    "        conn = psy.connect(\n",
    "            host=ssh_tunnel.local_bind_host,\n",
    "            port=ssh_tunnel.local_bind_port,\n",
    "            user='postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        print('Connection Made')\n",
    "        return conn\n",
    "    else:\n",
    "        conn = psy.connect(\n",
    "            host = DB_HOST,\n",
    "            port = 5432,\n",
    "            user = 'postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        print('Connection Made')\n",
    "        return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_sql(SSH_required, query,key_path):   #for getting a datafarame as a result\n",
    "\n",
    "    db='datawarehouse'\n",
    "    DB_HOST='datawarehouse.cdgpvetprks3.ap-south-1.rds.amazonaws.com'\n",
    "    conn = None\n",
    "    if SSH_required == 'Yes':\n",
    "        SSH_HOST='ec2-15-206-161-154.ap-south-1.compute.amazonaws.com'\n",
    "        #LOCALHOST=\"0.0.0.0\"\n",
    "        ssh_tunnel= SSHTunnelForwarder(\n",
    "                (SSH_HOST, 22),\n",
    "                ssh_username=\"ec2-user\",\n",
    "                ssh_private_key= key_path,\n",
    "                ssh_private_key_password= \"\",\n",
    "                remote_bind_address=(DB_HOST, 5432),\n",
    "                local_bind_address=('127.0.0.1', 0)\n",
    "        )\n",
    "        # ssh_tunnel._server_list[0].block_on_close = False\n",
    "        ssh_tunnel.start()\n",
    "        conn = psy.connect(\n",
    "            host=ssh_tunnel.local_bind_host,\n",
    "            port=ssh_tunnel.local_bind_port,\n",
    "            user='postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        df_results = pd.read_sql(query, conn)\n",
    "        conn.close()\n",
    "        ssh_tunnel.stop()\n",
    "        return df_results\n",
    "    else:\n",
    "        conn = psy.connect(\n",
    "            host = DB_HOST,\n",
    "            port = 5432,\n",
    "            user = 'postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        df_results = pd.read_sql(query, conn)\n",
    "        conn.close()\n",
    "        return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunnel Started\n",
      "Connection Made\n",
      "                 key1  warehouse_id pickup_vehicle          pickuptime  \\\n",
      "0      100-1514-Delhi          1514        Vishu.. 2024-07-07 21:14:28   \n",
      "1      100-1514-Delhi          1514        Vishu.. 2024-07-07 21:15:16   \n",
      "2      100-1514-Delhi          1514        Vishu.. 2024-07-07 21:15:20   \n",
      "3      100-1514-Delhi          1514        Vishu.. 2024-07-07 21:16:13   \n",
      "4      100-1514-Delhi          1514        Vishu.. 2024-07-07 21:16:41   \n",
      "...               ...           ...            ...                 ...   \n",
      "17934   87-327-Mumbai           327         mujeeb 2024-07-07 18:32:34   \n",
      "17935   87-327-Mumbai           327         mujeeb 2024-07-07 18:32:37   \n",
      "17936   87-327-Mumbai           327         mujeeb 2024-07-07 18:32:44   \n",
      "17937   87-327-Mumbai           327         mujeeb 2024-07-07 18:32:50   \n",
      "17938   87-327-Mumbai           327         mujeeb 2024-07-07 18:32:57   \n",
      "\n",
      "                awb  \n",
      "0      GS2038142560  \n",
      "1      GS2101548470  \n",
      "2      GS1389676432  \n",
      "3      GS1570758043  \n",
      "4      GS1810318091  \n",
      "...             ...  \n",
      "17934  GS2111834800  \n",
      "17935  GS2138786511  \n",
      "17936  GS1640791307  \n",
      "17937  GS1601090786  \n",
      "17938  GS1518043281  \n",
      "\n",
      "[17939 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Usage with the actual path to the private key\n",
    "SSH_required = 'Yes'\n",
    "key_path = '/Users/rajatsansaniwal/Documents/tunnel-ssh .cer'\n",
    "query_path = 'pickup_query.sql'\n",
    "with open(query_path,'r') as file:\n",
    "    query = file.read()\n",
    "\n",
    "# Establish a connection\n",
    "conn = get_conn(SSH_required, key_path)\n",
    "\n",
    "# Retrieve data into a DataFrame\n",
    "df = get_df_from_sql(SSH_required, query, key_path)\n",
    "\n",
    "# Now you can perform further operations with the DataFrame 'df'\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   key1  warehouse_id pickup_vehicle   pickup_start_time  \\\n",
      "0        100-1514-Delhi          1514        Vishu.. 2024-07-07 21:14:28   \n",
      "1        100-1514-Delhi          1514     Yellapa Ji 2024-07-07 11:19:47   \n",
      "2     100-329-Bangalore           329        Vishu.. 2024-07-07 21:14:22   \n",
      "3     100-329-Bangalore           329     Yellapa Ji 2024-07-07 11:19:35   \n",
      "4    101-1400-Hyderabad          1400   Chakali Raju 2024-07-07 18:55:06   \n",
      "..                  ...           ...            ...                 ...   \n",
      "163  449-2043-Bangalore          2043      Manjunath 2024-07-07 12:09:23   \n",
      "164  449-2043-Bangalore          2043        Vishu.. 2024-07-07 20:31:05   \n",
      "165      452-2140-Delhi          2140    Sohan singh 2024-07-07 12:03:30   \n",
      "166       87-1025-Delhi          1025      Karamveer 2024-07-07 09:51:18   \n",
      "167       87-327-Mumbai           327         mujeeb 2024-07-07 18:32:25   \n",
      "\n",
      "        pickup_end_time  slot_duration  gap_to_next  \n",
      "0   2024-07-07 21:24:13             10          NaN  \n",
      "1   2024-07-07 11:34:24             15          NaN  \n",
      "2   2024-07-07 21:22:36              9          NaN  \n",
      "3   2024-07-07 11:34:42             16          NaN  \n",
      "4   2024-07-07 19:11:24             17          NaN  \n",
      "..                  ...            ...          ...  \n",
      "163 2024-07-07 12:17:07              8          NaN  \n",
      "164 2024-07-07 20:43:46             13          NaN  \n",
      "165 2024-07-07 12:47:42             45          NaN  \n",
      "166 2024-07-07 09:51:22              1          NaN  \n",
      "167 2024-07-07 18:32:57              1          NaN  \n",
      "\n",
      "[168 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "df['pickuptime'] = pd.to_datetime(df['pickuptime'])\n",
    "\n",
    "results = []\n",
    "\n",
    "for (key1, warehouse, pickup_vehicle), group in df.groupby(['key1', 'warehouse_id', 'pickup_vehicle']):\n",
    "    group = group.reset_index(drop=True)\n",
    "\n",
    "    pickup_start_time = group.loc[0, 'pickuptime']\n",
    "\n",
    "    for i in range(1, len(group)):\n",
    "        current_time = group.loc[i, 'pickuptime']\n",
    "        previous_time = group.loc[i - 1, 'pickuptime']\n",
    "        \n",
    "        # Check the difference between current and previous pickuptime\n",
    "        if (current_time - previous_time).total_seconds() > 7200:  # More than two hours\n",
    "            # End the current pickup slot and start a new one\n",
    "            results.append({\n",
    "                'key1': key1,\n",
    "                'warehouse_id': warehouse,\n",
    "                'pickup_vehicle': pickup_vehicle,\n",
    "                'pickup_start_time': pickup_start_time,\n",
    "                'pickup_end_time': previous_time\n",
    "            })\n",
    "            pickup_start_time = current_time  # Update the start time for the new slot\n",
    "    \n",
    "    # Append the last slot for the warehouse\n",
    "    results.append({\n",
    "        'key1': key1,\n",
    "        'warehouse_id': warehouse,\n",
    "        'pickup_vehicle': pickup_vehicle,\n",
    "        'pickup_start_time': pickup_start_time,\n",
    "        'pickup_end_time': group.loc[len(group) - 1, 'pickuptime']\n",
    "    })\n",
    "\n",
    "# Create DataFrame from results list\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Calculate slot_duration in minutes\n",
    "results_df['slot_duration'] = ((results_df['pickup_end_time'] - results_df['pickup_start_time']).dt.total_seconds() / 60).apply(math.ceil)\n",
    "\n",
    "# Sort DataFrame by warehouse_id and pickup_start_time (if not already sorted)\n",
    "results_df.sort_values(by=['key1', 'warehouse_id', 'pickup_start_time'], inplace=True)\n",
    "\n",
    "# Calculate gaps between pickup slots in minutes\n",
    "results_df['gap_to_next'] = results_df.groupby(['key1', 'warehouse_id', 'pickup_vehicle'])['pickup_start_time'].shift(-1) - results_df['pickup_end_time']\n",
    "results_df['gap_to_next'] = (results_df['gap_to_next'].dt.total_seconds() / 60)\n",
    "results_df['gap_to_next'].fillna(0, inplace=True)\n",
    "results_df['gap_to_next'] = (results_df['gap_to_next'].astype(int) + 1).replace(1, np.nan)\n",
    "\n",
    "results_df.sort_values(by=['key1', 'warehouse_id', 'pickup_vehicle'], inplace=True)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   key1  warehouse_id pickup_vehicle   pickup_start_time  \\\n",
      "0        100-1514-Delhi          1514        Vishu.. 2024-07-07 21:14:28   \n",
      "1        100-1514-Delhi          1514     Yellapa Ji 2024-07-07 11:19:47   \n",
      "2     100-329-Bangalore           329        Vishu.. 2024-07-07 21:14:22   \n",
      "3     100-329-Bangalore           329     Yellapa Ji 2024-07-07 11:19:35   \n",
      "4    101-1400-Hyderabad          1400   Chakali Raju 2024-07-07 18:55:06   \n",
      "..                  ...           ...            ...                 ...   \n",
      "163  449-2043-Bangalore          2043      Manjunath 2024-07-07 12:09:23   \n",
      "164  449-2043-Bangalore          2043        Vishu.. 2024-07-07 20:31:05   \n",
      "165      452-2140-Delhi          2140    Sohan singh 2024-07-07 12:03:30   \n",
      "166       87-1025-Delhi          1025      Karamveer 2024-07-07 09:51:18   \n",
      "167       87-327-Mumbai           327         mujeeb 2024-07-07 18:32:25   \n",
      "\n",
      "        pickup_end_time  slot_duration  gap_to_next  actual_load  \n",
      "0   2024-07-07 21:24:13             10          NaN           28  \n",
      "1   2024-07-07 11:34:24             15          NaN           63  \n",
      "2   2024-07-07 21:22:36              9          NaN           51  \n",
      "3   2024-07-07 11:34:42             16          NaN          144  \n",
      "4   2024-07-07 19:11:24             17          NaN           65  \n",
      "..                  ...            ...          ...          ...  \n",
      "163 2024-07-07 12:17:07              8          NaN           44  \n",
      "164 2024-07-07 20:43:46             13          NaN          145  \n",
      "165 2024-07-07 12:47:42             45          NaN          269  \n",
      "166 2024-07-07 09:51:22              1          NaN            2  \n",
      "167 2024-07-07 18:32:57              1          NaN            7  \n",
      "\n",
      "[168 rows x 8 columns]\n",
      "DataFrame saved to pickup_slots.xlsx\n"
     ]
    }
   ],
   "source": [
    "loads = []\n",
    "\n",
    "for index, row in results_df.iterrows():\n",
    "    key1 = row['key1']\n",
    "    warehouse_id = row['warehouse_id']\n",
    "    pickup_vehicle = row['pickup_vehicle']\n",
    "    slot_start_time = row['pickup_start_time']\n",
    "    slot_end_time = row['pickup_end_time']\n",
    "    \n",
    "    load = 0  # Initialize load count for this slot\n",
    "\n",
    "    filtered_df = df[(df['key1'] == key1) &\n",
    "                     (df['warehouse_id'] == warehouse_id) &\n",
    "                     (df['pickup_vehicle'] == pickup_vehicle) &\n",
    "                     (df['pickuptime'] >= slot_start_time) &\n",
    "                     (df['pickuptime'] <= slot_end_time)]\n",
    "\n",
    "    # Count the number of AWBs within the slot time range and add to load\n",
    "    load += len(filtered_df)\n",
    "    \n",
    "    # Append the total load count for this slot to the loads list\n",
    "    loads.append(load)\n",
    "\n",
    "# Assign the 'actual_load' column to results_df using the loads list\n",
    "results_df['actual_load'] = loads\n",
    "\n",
    "# Print or display the updated DataFrame with the 'actual_load' column\n",
    "print(results_df)\n",
    "\n",
    "# Save DataFrame to Excel\n",
    "excel_file = 'pickup_slots.xlsx'\n",
    "results_df.to_excel(excel_file, index=False)\n",
    "\n",
    "print(f\"DataFrame saved to {excel_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
