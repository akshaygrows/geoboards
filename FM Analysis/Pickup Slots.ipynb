{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1087,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, time\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "import psycopg2 as psy\n",
    "import math\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining function to get a dataframe from sql\n",
    "\n",
    "def get_df_from_sql(SSH_required, query,key_path):\n",
    "\n",
    "    db='datawarehouse'\n",
    "    DB_HOST='datawarehouse.cdgpvetprks3.ap-south-1.rds.amazonaws.com'\n",
    "    conn = None\n",
    "    if SSH_required == 'Yes':\n",
    "        SSH_HOST='ec2-15-206-161-154.ap-south-1.compute.amazonaws.com'\n",
    "        #LOCALHOST=\"0.0.0.0\"\n",
    "        ssh_tunnel= SSHTunnelForwarder(\n",
    "                (SSH_HOST, 22),\n",
    "                ssh_username=\"ec2-user\",\n",
    "                ssh_private_key= key_path,\n",
    "                ssh_private_key_password= \"\",\n",
    "                remote_bind_address=(DB_HOST, 5432),\n",
    "                local_bind_address=('127.0.0.1', 0)\n",
    "        )\n",
    "        # ssh_tunnel._server_list[0].block_on_close = False\n",
    "        ssh_tunnel.start()\n",
    "        conn = psy.connect(\n",
    "            host=ssh_tunnel.local_bind_host,\n",
    "            port=ssh_tunnel.local_bind_port,\n",
    "            user='postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        df_results = pd.read_sql(query, conn)\n",
    "        conn.close()\n",
    "        ssh_tunnel.stop()\n",
    "        return df_results\n",
    "    else:\n",
    "        conn = psy.connect(\n",
    "            host = DB_HOST,\n",
    "            port = 5432,\n",
    "            user = 'postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        df_results = pd.read_sql(query, conn)\n",
    "        conn.close()\n",
    "        return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the dataframe from sql query on ops main\n",
    "\n",
    "SSH_required = 'Yes'\n",
    "key_path = '/Users/rajatsansaniwal/Documents/tunnel-ssh .cer'\n",
    "query_path = 'pickup_query.sql'\n",
    "with open(query_path,'r') as file:\n",
    "    query = file.read()\n",
    "\n",
    "df = get_df_from_sql(SSH_required, query, key_path)\n",
    "# df = df[df['warehouse_id'] == 1514]\n",
    "\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making pickup slots on warehouses and pickup vehicle\n",
    "\n",
    "df['pickuptime'] = pd.to_datetime(df['pickuptime'])\n",
    "\n",
    "results = []\n",
    "\n",
    "for (key, warehouse, pickup_vehicle), group in df.groupby(['key', 'warehouse_id', 'pickup_vehicle']):\n",
    "    group = group.reset_index(drop=True)\n",
    "\n",
    "    pickup_start_time = group.loc[0, 'pickuptime']\n",
    "\n",
    "    for i in range(1, len(group)):\n",
    "        current_time = group.loc[i, 'pickuptime']\n",
    "        previous_time = group.loc[i - 1, 'pickuptime']\n",
    "        \n",
    "        # Check the difference between current and previous pickuptime\n",
    "        if (current_time - previous_time).total_seconds() > 7200:  # More than two hours\n",
    "            # End the current pickup slot and start a new one\n",
    "            results.append({\n",
    "                'key': key,\n",
    "                'warehouse_id': warehouse,\n",
    "                'pickup_vehicle': pickup_vehicle,\n",
    "                'pickup_start_time': pickup_start_time,\n",
    "                'pickup_end_time': previous_time\n",
    "            })\n",
    "            pickup_start_time = current_time  # Update the start time for the new slot\n",
    "    \n",
    "    # Append the last slot for the warehouse\n",
    "    results.append({\n",
    "        'key': key,\n",
    "        'warehouse_id': warehouse,\n",
    "        'pickup_vehicle': pickup_vehicle,\n",
    "        'pickup_start_time': pickup_start_time,\n",
    "        'pickup_end_time': group.loc[len(group) - 1, 'pickuptime']\n",
    "    })\n",
    "\n",
    "# Create DataFrame from results list\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Calculate slot_duration in minutes\n",
    "results_df['slot_duration'] = ((results_df['pickup_end_time'] - results_df['pickup_start_time']).dt.total_seconds() / 60).apply(math.ceil)\n",
    "\n",
    "# Sort DataFrame by warehouse_id and pickup_start_time (if not already sorted)\n",
    "results_df.sort_values(by=['key', 'warehouse_id', 'pickup_start_time'], inplace=True)\n",
    "\n",
    "# Calculate gaps between pickup slots in minutes\n",
    "results_df['gap_to_next'] = results_df.groupby(['key', 'warehouse_id', 'pickup_vehicle'])['pickup_start_time'].shift(-1) - results_df['pickup_end_time']\n",
    "results_df['gap_to_next'] = (results_df['gap_to_next'].dt.total_seconds() / 60)\n",
    "results_df['gap_to_next'].fillna(0, inplace=True)\n",
    "results_df['gap_to_next'] = (results_df['gap_to_next'].astype(int) + 1).replace(1, np.nan)\n",
    "\n",
    "results_df.sort_values(by=['key', 'warehouse_id', 'pickup_vehicle'], inplace=True)\n",
    "\n",
    "# print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding actual load on slots\n",
    "\n",
    "loads = []\n",
    "\n",
    "for index, row in results_df.iterrows():\n",
    "    key = row['key']\n",
    "    warehouse_id = row['warehouse_id']\n",
    "    pickup_vehicle = row['pickup_vehicle']\n",
    "    slot_start_time = row['pickup_start_time']\n",
    "    slot_end_time = row['pickup_end_time']\n",
    "    \n",
    "    load = 0  # Initialize load count for this slot\n",
    "\n",
    "    filtered_df = df[(df['key'] == key) &\n",
    "                     (df['warehouse_id'] == warehouse_id) &\n",
    "                     (df['pickup_vehicle'] == pickup_vehicle) &\n",
    "                     (df['pickuptime'] >= slot_start_time) &\n",
    "                     (df['pickuptime'] <= slot_end_time)]\n",
    "\n",
    "    # Count the number of AWBs within the slot time range and add to load\n",
    "    load += len(filtered_df)\n",
    "    \n",
    "    # Append the total load count for this slot to the loads list\n",
    "    loads.append(load)\n",
    "\n",
    "# Assign the 'actual_load' column to results_df using the loads list\n",
    "results_df['actual_load'] = loads\n",
    "pickup_slots_df = results_df\n",
    "\n",
    "# # Print or display the updated DataFrame with the 'actual_load' column\n",
    "# print(pickup_slots_df)\n",
    "\n",
    "# # Save DataFrame to Excel\n",
    "# excel_file = 'pickup_slots.xlsx'\n",
    "# pickup_slots_df.to_excel(excel_file, index=False)\n",
    "\n",
    "# print(f\"DataFrame saved to {excel_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading pickup cutoff time data\n",
    "\n",
    "query_path = 'pickup_cutoff_time.sql'\n",
    "with open(query_path,'r') as file:\n",
    "    query = file.read()\n",
    "\n",
    "pickup_cutoff_df = get_df_from_sql(SSH_required, query, key_path)\n",
    "\n",
    "pickup_cutoff_df['pickup_cutoff'] = pd.to_datetime(pickup_cutoff_df['pickup_cutoff'], format='%H:%M:%S', errors='coerce').dt.time\n",
    "# pickup_cutoff_df = pickup_cutoff_df[pickup_cutoff_df['warehouse_id'] == 1514]\n",
    "# display(pickup_cutoff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expanding cut off time data to a cut off datetime data with range of [d-3, d] days i.e. 4 days\n",
    "\n",
    "# print(datetime.now())\n",
    "\n",
    "# Step 1: Define the range of dates\n",
    "start_date = datetime.now() - timedelta(days=3)  # Adjusted start date, datetime.now() is in IST already\n",
    "end_date = datetime.now()\n",
    "\n",
    "# Step 2: Create a new DataFrame to hold the expanded rows\n",
    "expanded_rows = []\n",
    "\n",
    "# Iterate through each row in pickup_cutoff_df\n",
    "for index, row in pickup_cutoff_df.iterrows():\n",
    "    key = row['key']\n",
    "    warehouse_id = row['warehouse_id']\n",
    "    pickup_cutoff = row['pickup_cutoff']\n",
    "\n",
    "    # Iterate through each date in the range\n",
    "    date_iterator = start_date\n",
    "    while date_iterator <= end_date:\n",
    "        # Combine current date with pickup_cutoff_time to create datetime\n",
    "        pickup_datetime = datetime.combine(date_iterator.date(), pickup_cutoff)\n",
    "\n",
    "        # Append row with key, pickup_cutoff_time, and current date\n",
    "        expanded_rows.append({\n",
    "            'key': key,\n",
    "            'warehouse_id': warehouse_id,\n",
    "            'pickup_cutoff': pickup_cutoff,\n",
    "            'pickup_cutoff_time1': pickup_datetime\n",
    "        })\n",
    "\n",
    "        # Move to the next date\n",
    "        date_iterator += timedelta(days=1)\n",
    "\n",
    "# Create DataFrame from expanded rows\n",
    "expanded_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "merged_df = pd.merge(pickup_cutoff_df, expanded_df, left_on=['key', 'warehouse_id', 'pickup_cutoff'], right_on=['key', 'warehouse_id', 'pickup_cutoff'], how='left')\n",
    "\n",
    "# Drop pickup_cutoff_time and rename pickup_cutoff_time1\n",
    "merged_df.drop(columns=['pickup_cutoff'], inplace=True)\n",
    "merged_df.rename(columns={'pickup_cutoff_time1': 'pickup_cutoff'}, inplace=True)\n",
    "pickup_cutoff_df = merged_df\n",
    "\n",
    "# Display the expanded DataFrame\n",
    "# print(pickup_cutoff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matching pickups that happened with every possible pickup cutoff time\n",
    "\n",
    "final_df = pd.merge(pickup_slots_df, pickup_cutoff_df, left_on = ['key', 'warehouse_id'], right_on = ['key', 'warehouse_id'], how='left')\n",
    "# display(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some warehouse ids that are active but are not in pickup_cutoff_time, we are dropping them, but they need to be added in excel.pickup_cutoff_time\n",
    "\n",
    "final_df.dropna(subset=['pickup_cutoff'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing rows with right pickup cutoff matching\n",
    "\n",
    "final_df['slot_id'] = final_df['warehouse_id'].astype(str) + '-' + final_df['pickup_vehicle'].astype(str) + '-' + final_df['pickup_start_time'].astype(str)\n",
    "\n",
    "# Calculate the duration and take the absolute value to see nearest cutoff time\n",
    "final_df['start_to_pickup_cutoff'] = (final_df['pickup_start_time'] - final_df['pickup_cutoff']).abs()\n",
    "final_df['end_to_pickup_cutoff'] = (final_df['pickup_end_time'] - final_df['pickup_cutoff']).abs()\n",
    "# display(final_df)\n",
    "\n",
    "# Function to apply the rules\n",
    "def filter_rows(group):\n",
    "    # Rule 1: If start_to_pickup_cutoff < 1 hour\n",
    "    rule_1 = group[group['start_to_pickup_cutoff'] < pd.Timedelta(hours=1)]\n",
    "    if not rule_1.empty:\n",
    "        return rule_1.iloc[[0]]\n",
    "\n",
    "    # Rule 2: If end_to_pickup_cutoff < 1 hour\n",
    "    rule_2 = group[group['end_to_pickup_cutoff'] < pd.Timedelta(hours=1)]\n",
    "    if not rule_2.empty:\n",
    "        return rule_2.iloc[[0]]\n",
    "\n",
    "    # Rule 3: If pickup_cutoff_time is within pickup_start_time and pickup_end_time\n",
    "    rule_3 = group[(group['pickup_cutoff'] >= group['pickup_start_time']) & (group['pickup_cutoff'] <= group['pickup_end_time'])]\n",
    "    if not rule_3.empty:\n",
    "        return rule_3.iloc[[0]]\n",
    "\n",
    "    # Rule 4: Closest pickup_cutoff_time < pickup_start_time\n",
    "    group['diff'] = (group['pickup_start_time'] - group['pickup_cutoff']).abs()\n",
    "    rule_4 = group[group['pickup_cutoff'] < group['pickup_start_time']]\n",
    "    if not rule_4.empty:\n",
    "        return rule_4.loc[[rule_4['diff'].idxmin()]]\n",
    "    \n",
    "    return pd.DataFrame()  # If no rule matches, return an empty DataFrame\n",
    "\n",
    "# Apply the function to each group of slot_id\n",
    "final_df = final_df.groupby('slot_id').apply(filter_rows).reset_index(drop=True)\n",
    "\n",
    "# Drop the auxiliary column used for Rule 4\n",
    "final_df.drop(columns=['diff'], inplace=True)\n",
    "\n",
    "# display(final_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning data\n",
    "\n",
    "final_df = final_df[['key', 'warehouse_id', 'pickup_vehicle', 'pickup_cutoff', 'pickup_start_time', 'pickup_end_time', 'actual_load']]\n",
    "final_df = final_df.sort_values(by= ['key', 'pickup_cutoff'])\n",
    "final_df = final_df.reset_index(drop=True)\n",
    "\n",
    "summary_df = final_df.groupby(['key', 'warehouse_id', 'pickup_cutoff']).agg({\n",
    "    'pickup_start_time': 'min',\n",
    "    'pickup_end_time': 'max',\n",
    "    'actual_load': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Display the summary DataFrame\n",
    "# display(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1098,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensures Missed Pickups are there\n",
    "\n",
    "expanded_df.drop(columns=['pickup_cutoff'], inplace=True)\n",
    "expanded_df.rename(columns={'pickup_cutoff_time1':'pickup_cutoff'}, inplace=True)\n",
    "expanded_df.sort_values(by=['key', 'pickup_cutoff'], inplace=True)\n",
    "\n",
    "\n",
    "# print(expanded_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating final table\n",
    "\n",
    "final = pd.merge(expanded_df, summary_df, left_on=['key', 'warehouse_id', 'pickup_cutoff'], right_on=['key', 'warehouse_id', 'pickup_cutoff'], how='left')\n",
    "# display(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100-1514-Bangalore', '101-732-Mumbai', '102-328-Mumbai', '185-359-Hyderabad', '204-815-Mumbai', '222-1394-Mumbai', '31-1534-Delhi', '31-1585-Bangalore', '31-1892-Mumbai', '31-65-Mumbai', '317-1626-Delhi', '327-182-Bangalore', '334-1425-Mumbai', '334-1491-Bangalore', '334-1504-Delhi', '340-1449-Delhi', '341-1453-Delhi', '359-1373-Delhi', '364-1558-Mumbai', '364-1590-Bangalore', '364-1590-Hyderabad', '364-1631-Hyderabad', '364-1721-Delhi', '364-1721-Jaipur', '364-1721-NCR', '374-1554-Delhi', '376-1623-Bangalore', '376-1661-Bangalore', '376-1670-Bangalore', '376-1672-Mumbai', '376-1710-Bangalore', '376-1879-Delhi', '376-1883-Delhi', '376-2001-Delhi', '377-1527-Hyderabad', '377-1571-Delhi', '378-1625-Mumbai', '378-1817-Delhi', '381-1614-Bangalore', '381-1639-Bangalore', '381-1669-Delhi', '381-1678-Mumbai', '381-1681-Hyderabad', '381-1687-Bangalore', '381-1688-Bangalore', '381-1723-Bangalore', '381-1758-Hyderabad', '381-1818-Hyderabad', '381-1853-Bangalore', '381-1952-Delhi', '381-1960-Delhi', '381-1961-Delhi', '381-1963-Delhi', '381-1999-Bangalore', '381-2057-Bangalore', '381-2058-Bangalore', '381-2059-Bangalore', '381-2099-Hyderabad', '382-1545-Delhi', '382-1846-Delhi', '389-1901-Delhi', '389-1931-Delhi', '389-1949-Delhi', '401-1966-Mumbai', '401-1981-Bangalore', '402-1693-Mumbai', '406-1894-Delhi', '407-1736-Delhi', '411-1826-Bangalore', '411-1827-Bangalore', '411-1837-Bangalore', '411-1842-Bangalore', '411-2098-Bangalore', '417-2054-Delhi', '417-2055-Delhi', '417-2074-Delhi', '428-1871-Delhi', '435-1980-Delhi', '44-737-Mumbai', '442-2023-Mumbai', '443-2025-Mumbai', '445-2029-Mumbai', '51-1373-Delhi', '81-250-Hyderabad', '81-370-Bangalore', '81-833-Delhi']\n"
     ]
    }
   ],
   "source": [
    "# Removing warehouses with no activity in all last 4 days\n",
    "\n",
    "# Find all key values where pickup_start_time is NaT on all dates and remove them\n",
    "key_with_all_NaT = final.groupby('key').filter(lambda x: x['pickup_start_time'].isna().all())['key'].unique()\n",
    "\n",
    "# Convert the result to a list\n",
    "key_with_all_NaT_list = key_with_all_NaT.tolist()\n",
    "\n",
    "# Print the list\n",
    "print(key_with_all_NaT_list)\n",
    "\n",
    "final = final[~final['key'].isin(key_with_all_NaT_list)]\n",
    "final['pickup_duration'] = final['pickup_end_time'] - final['pickup_start_time']\n",
    "# display(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>pickup_cutoff</th>\n",
       "      <th>pickup_start_time</th>\n",
       "      <th>pickup_end_time</th>\n",
       "      <th>actual_load</th>\n",
       "      <th>pickup_duration</th>\n",
       "      <th>pickup_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100-1514-Delhi</td>\n",
       "      <td>1514</td>\n",
       "      <td>2024-07-12 11:00:00</td>\n",
       "      <td>2024-07-12 11:12:55</td>\n",
       "      <td>2024-07-12 11:33:01</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0 days 00:20:06</td>\n",
       "      <td>On-time pickup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100-1514-Delhi</td>\n",
       "      <td>1514</td>\n",
       "      <td>2024-07-12 17:30:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Missed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100-1514-Delhi</td>\n",
       "      <td>1514</td>\n",
       "      <td>2024-07-13 11:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Missed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100-1514-Delhi</td>\n",
       "      <td>1514</td>\n",
       "      <td>2024-07-13 17:30:00</td>\n",
       "      <td>2024-07-13 17:41:38</td>\n",
       "      <td>2024-07-13 17:44:01</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0 days 00:02:23</td>\n",
       "      <td>On-time pickup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100-1514-Delhi</td>\n",
       "      <td>1514</td>\n",
       "      <td>2024-07-14 11:00:00</td>\n",
       "      <td>2024-07-14 11:20:50</td>\n",
       "      <td>2024-07-14 11:20:50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>On-time pickup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>87-1025-Delhi</td>\n",
       "      <td>1025</td>\n",
       "      <td>2024-07-15 10:30:00</td>\n",
       "      <td>2024-07-15 09:42:19</td>\n",
       "      <td>2024-07-15 09:42:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>On-time pickup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>87-327-Mumbai</td>\n",
       "      <td>327</td>\n",
       "      <td>2024-07-12 16:00:00</td>\n",
       "      <td>2024-07-12 18:18:03</td>\n",
       "      <td>2024-07-12 18:18:55</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0 days 00:00:52</td>\n",
       "      <td>Late pickup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>87-327-Mumbai</td>\n",
       "      <td>327</td>\n",
       "      <td>2024-07-13 16:00:00</td>\n",
       "      <td>2024-07-13 19:01:38</td>\n",
       "      <td>2024-07-13 19:01:49</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0 days 00:00:11</td>\n",
       "      <td>Late pickup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>87-327-Mumbai</td>\n",
       "      <td>327</td>\n",
       "      <td>2024-07-14 16:00:00</td>\n",
       "      <td>2024-07-14 17:55:26</td>\n",
       "      <td>2024-07-14 17:55:36</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0 days 00:00:10</td>\n",
       "      <td>Late pickup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>87-327-Mumbai</td>\n",
       "      <td>327</td>\n",
       "      <td>2024-07-15 16:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Pending</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>572 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                key  warehouse_id       pickup_cutoff   pickup_start_time  \\\n",
       "4    100-1514-Delhi          1514 2024-07-12 11:00:00 2024-07-12 11:12:55   \n",
       "5    100-1514-Delhi          1514 2024-07-12 17:30:00                 NaT   \n",
       "6    100-1514-Delhi          1514 2024-07-13 11:00:00                 NaT   \n",
       "7    100-1514-Delhi          1514 2024-07-13 17:30:00 2024-07-13 17:41:38   \n",
       "8    100-1514-Delhi          1514 2024-07-14 11:00:00 2024-07-14 11:20:50   \n",
       "..              ...           ...                 ...                 ...   \n",
       "923   87-1025-Delhi          1025 2024-07-15 10:30:00 2024-07-15 09:42:19   \n",
       "924   87-327-Mumbai           327 2024-07-12 16:00:00 2024-07-12 18:18:03   \n",
       "925   87-327-Mumbai           327 2024-07-13 16:00:00 2024-07-13 19:01:38   \n",
       "926   87-327-Mumbai           327 2024-07-14 16:00:00 2024-07-14 17:55:26   \n",
       "927   87-327-Mumbai           327 2024-07-15 16:00:00                 NaT   \n",
       "\n",
       "        pickup_end_time  actual_load pickup_duration   pickup_status  \n",
       "4   2024-07-12 11:33:01         57.0 0 days 00:20:06  On-time pickup  \n",
       "5                   NaT          NaN             NaT          Missed  \n",
       "6                   NaT          NaN             NaT          Missed  \n",
       "7   2024-07-13 17:44:01          7.0 0 days 00:02:23  On-time pickup  \n",
       "8   2024-07-14 11:20:50          1.0 0 days 00:00:00  On-time pickup  \n",
       "..                  ...          ...             ...             ...  \n",
       "923 2024-07-15 09:42:19          1.0 0 days 00:00:00  On-time pickup  \n",
       "924 2024-07-12 18:18:55         10.0 0 days 00:00:52     Late pickup  \n",
       "925 2024-07-13 19:01:49          3.0 0 days 00:00:11     Late pickup  \n",
       "926 2024-07-14 17:55:36          4.0 0 days 00:00:10     Late pickup  \n",
       "927                 NaT          NaN             NaT         Pending  \n",
       "\n",
       "[572 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating status column\n",
    "\n",
    "# Step 1: Check if 'pickup_status' column exists, if not, initialize it\n",
    "if 'pickup_status' not in final.columns:\n",
    "    final['pickup_status'] = np.nan\n",
    "\n",
    "# Step 2: Preserve the 'Missed' status\n",
    "missed_mask = final['pickup_status'] == 'Missed'\n",
    "\n",
    "# Step 3: Define the conditions\n",
    "conditions = [\n",
    "    (final['pickup_start_time'].notna() & (final['pickup_start_time'] <= final['pickup_cutoff'] + pd.Timedelta(minutes=30))),\n",
    "    (final['pickup_start_time'].notna() & (final['pickup_start_time'] > final['pickup_cutoff'] + pd.Timedelta(minutes=30))),\n",
    "    (final['pickup_start_time'].isna() & (final['pickup_cutoff'] + pd.Timedelta(hours=6, minutes=30) < current_time)),\n",
    "    (final['pickup_start_time'].isna() & (final['pickup_cutoff'] + pd.Timedelta(minutes=30) <= current_time)),\n",
    "    (final['pickup_start_time'].isna() & (final['pickup_cutoff'] + pd.Timedelta(minutes=30) > current_time))\n",
    "]\n",
    "\n",
    "# Define the corresponding values for the conditions\n",
    "choices = [\n",
    "    'On-time pickup',\n",
    "    'Late pickup',\n",
    "    'Missed',\n",
    "    'Delayed',\n",
    "    'Pending'\n",
    "]\n",
    "\n",
    "# Step 4: Apply the conditions to update the 'pickup_status' column\n",
    "final['pickup_status'] = np.select(conditions, choices, default='Unknown')\n",
    "\n",
    "# Step 5: Reapply the 'Missed' status\n",
    "final.loc[missed_mask, 'pickup_status'] = 'Missed'\n",
    "\n",
    "# Display the final DataFrame\n",
    "display(final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'final_fm.xlsx'\n",
    "final['pickup_duration'] = final['pickup_duration'].astype(str)\n",
    "final.to_excel(filepath, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
