{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "import psycopg2 as psy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conn(SSH_required,key_path):   #for getting a connection as a result\n",
    "\n",
    "    db='datawarehouse'\n",
    "    DB_HOST='datawarehouse.cdgpvetprks3.ap-south-1.rds.amazonaws.com'\n",
    "    conn = []\n",
    "    if SSH_required == 'Yes':\n",
    "        SSH_HOST='ec2-15-206-161-154.ap-south-1.compute.amazonaws.com'\n",
    "        #LOCALHOST=\"0.0.0.0\"\n",
    "        ssh_tunnel= SSHTunnelForwarder(\n",
    "                (SSH_HOST, 22),\n",
    "                ssh_username=\"ec2-user\",\n",
    "                ssh_private_key= key_path,\n",
    "                ssh_private_key_password= \"\",\n",
    "                remote_bind_address=(DB_HOST, 5432),\n",
    "                local_bind_address=('127.0.0.1', 0)\n",
    "        )\n",
    "        print('Tunnel Started')\n",
    "        ssh_tunnel.start()\n",
    "        conn = psy.connect(\n",
    "            host=ssh_tunnel.local_bind_host,\n",
    "            port=ssh_tunnel.local_bind_port,\n",
    "            user='postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        print('Connection Made')\n",
    "        return conn\n",
    "    else:\n",
    "        conn = psy.connect(\n",
    "            host = DB_HOST,\n",
    "            port = 5432,\n",
    "            user = 'postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        print('Connection Made')\n",
    "        return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_sql(SSH_required, query,key_path):   #for getting a datafarame as a result\n",
    "\n",
    "    db='datawarehouse'\n",
    "    DB_HOST='datawarehouse.cdgpvetprks3.ap-south-1.rds.amazonaws.com'\n",
    "    conn = None\n",
    "    if SSH_required == 'Yes':\n",
    "        SSH_HOST='ec2-15-206-161-154.ap-south-1.compute.amazonaws.com'\n",
    "        #LOCALHOST=\"0.0.0.0\"\n",
    "        ssh_tunnel= SSHTunnelForwarder(\n",
    "                (SSH_HOST, 22),\n",
    "                ssh_username=\"ec2-user\",\n",
    "                ssh_private_key= key_path,\n",
    "                ssh_private_key_password= \"\",\n",
    "                remote_bind_address=(DB_HOST, 5432),\n",
    "                local_bind_address=('127.0.0.1', 0)\n",
    "        )\n",
    "        # ssh_tunnel._server_list[0].block_on_close = False\n",
    "        ssh_tunnel.start()\n",
    "        conn = psy.connect(\n",
    "            host=ssh_tunnel.local_bind_host,\n",
    "            port=ssh_tunnel.local_bind_port,\n",
    "            user='postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        df_results = pd.read_sql(query, conn)\n",
    "        conn.close()\n",
    "        ssh_tunnel.stop()\n",
    "        return df_results\n",
    "    else:\n",
    "        conn = psy.connect(\n",
    "            host = DB_HOST,\n",
    "            port = 5432,\n",
    "            user = 'postgres',\n",
    "            password= \"Simply1234\",\n",
    "            database='postgres')\n",
    "        df_results = pd.read_sql(query, conn)\n",
    "        conn.close()\n",
    "        return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunnel Started\n",
      "Connection Made\n",
      "       warehouse_id          pickuptime           awb\n",
      "0                83 2024-07-06 16:49:33  GS1785205670\n",
      "1                83 2024-07-06 16:49:36  GS2006391816\n",
      "2                83 2024-07-06 16:49:39  GS1166207635\n",
      "3                83 2024-07-06 16:49:42  GS1053787147\n",
      "4                83 2024-07-06 16:49:47  GS1758550671\n",
      "...             ...                 ...           ...\n",
      "17426          2147 2024-07-06 12:25:24  GS1945488003\n",
      "17427          2147 2024-07-06 12:25:40  GS2022778763\n",
      "17428          2147 2024-07-06 12:25:42  GS1524706122\n",
      "17429          2151 2024-07-06 16:46:59  GS1812158876\n",
      "17430          2151 2024-07-06 16:47:04  GS1755804579\n",
      "\n",
      "[17431 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Usage with the actual path to the private key\n",
    "SSH_required = 'Yes'\n",
    "key_path = '/Users/rajatsansaniwal/Documents/tunnel-ssh .cer'\n",
    "query_path = 'pickup_query.sql'\n",
    "with open(query_path,'r') as file:\n",
    "    query = file.read()\n",
    "\n",
    "# Establish a connection\n",
    "conn = get_conn(SSH_required, key_path)\n",
    "\n",
    "# Retrieve data into a DataFrame\n",
    "df = get_df_from_sql(SSH_required, query, key_path)\n",
    "\n",
    "# Now you can perform further operations with the DataFrame 'df'\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     warehouse_id   pickup_start_time     pickup_end_time  slot_duration  \\\n",
      "0              83 2024-07-06 16:49:33 2024-07-06 16:55:17              6   \n",
      "1             314 2024-07-06 01:40:19 2024-07-06 02:06:12             26   \n",
      "2             314 2024-07-06 15:42:51 2024-07-06 16:06:08             24   \n",
      "3             314 2024-07-06 17:37:28 2024-07-06 17:45:11              8   \n",
      "4             327 2024-07-06 18:49:49 2024-07-06 18:50:15              1   \n",
      "..            ...                 ...                 ...            ...   \n",
      "214          2142 2024-07-06 17:53:20 2024-07-06 17:53:58              1   \n",
      "215          2143 2024-07-06 18:54:56 2024-07-06 19:07:06             13   \n",
      "216          2144 2024-07-06 18:54:05 2024-07-06 19:07:28             14   \n",
      "217          2147 2024-07-06 12:23:09 2024-07-06 12:25:42              3   \n",
      "218          2151 2024-07-06 16:46:59 2024-07-06 16:47:04              1   \n",
      "\n",
      "     gap_to_next  \n",
      "0            NaN  \n",
      "1          817.0  \n",
      "2           92.0  \n",
      "3            NaN  \n",
      "4            NaN  \n",
      "..           ...  \n",
      "214          NaN  \n",
      "215          NaN  \n",
      "216          NaN  \n",
      "217          NaN  \n",
      "218          NaN  \n",
      "\n",
      "[219 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df['pickuptime'] = pd.to_datetime(df['pickuptime'])\n",
    "\n",
    "results = []\n",
    "\n",
    "for warehouse, group in df.groupby('warehouse_id'):\n",
    "    group = group.reset_index(drop=True)\n",
    "\n",
    "    pickup_start_time = group.loc[0, 'pickuptime']\n",
    "\n",
    "    for i in range(1, len(group)):\n",
    "        current_time = group.loc[i, 'pickuptime']\n",
    "        previous_time = group.loc[i - 1, 'pickuptime']\n",
    "        \n",
    "        # Check the difference between current and previous pickuptime\n",
    "        if (current_time - previous_time).total_seconds() > 3600:  # More than one hour\n",
    "            # End the current pickup slot and start a new one\n",
    "            results.append({\n",
    "                'warehouse_id': warehouse,\n",
    "                'pickup_start_time': pickup_start_time,\n",
    "                'pickup_end_time': previous_time\n",
    "            })\n",
    "            pickup_start_time = current_time  # Update the start time for the new slot\n",
    "    \n",
    "    # Append the last slot for the warehouse\n",
    "    results.append({\n",
    "        'warehouse_id': warehouse,\n",
    "        'pickup_start_time': pickup_start_time,\n",
    "        'pickup_end_time': group.loc[len(group) - 1, 'pickuptime']\n",
    "    })\n",
    "\n",
    "# Create DataFrame from results list\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Calculate slot_duration in minutes\n",
    "results_df['slot_duration'] = ((results_df['pickup_end_time'] - results_df['pickup_start_time']).dt.total_seconds() / 60).apply(math.ceil)\n",
    "\n",
    "# Sort DataFrame by warehouse_id and pickup_start_time (if not already sorted)\n",
    "results_df.sort_values(by=['warehouse_id', 'pickup_start_time'], inplace=True)\n",
    "\n",
    "# Calculate gaps between pickup slots in minutes\n",
    "results_df['gap_to_next'] = results_df.groupby('warehouse_id')['pickup_start_time'].shift(-1) - results_df['pickup_end_time']\n",
    "results_df['gap_to_next'] = (results_df['gap_to_next'].dt.total_seconds() / 60)\n",
    "results_df['gap_to_next'].fillna(0, inplace=True)\n",
    "results_df['gap_to_next'] = (results_df['gap_to_next'].astype(int) + 1).replace(1, np.nan)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     warehouse_id   pickup_start_time     pickup_end_time  slot_duration  \\\n",
      "0              83 2024-07-06 16:49:33 2024-07-06 16:55:17              6   \n",
      "1             314 2024-07-06 01:40:19 2024-07-06 02:06:12             26   \n",
      "2             314 2024-07-06 15:42:51 2024-07-06 16:06:08             24   \n",
      "3             314 2024-07-06 17:37:28 2024-07-06 17:45:11              8   \n",
      "4             327 2024-07-06 18:49:49 2024-07-06 18:50:15              1   \n",
      "..            ...                 ...                 ...            ...   \n",
      "214          2142 2024-07-06 17:53:20 2024-07-06 17:53:58              1   \n",
      "215          2143 2024-07-06 18:54:56 2024-07-06 19:07:06             13   \n",
      "216          2144 2024-07-06 18:54:05 2024-07-06 19:07:28             14   \n",
      "217          2147 2024-07-06 12:23:09 2024-07-06 12:25:42              3   \n",
      "218          2151 2024-07-06 16:46:59 2024-07-06 16:47:04              1   \n",
      "\n",
      "     gap_to_next  actual_load  \n",
      "0            NaN           47  \n",
      "1          817.0            2  \n",
      "2           92.0          128  \n",
      "3            NaN           89  \n",
      "4            NaN            6  \n",
      "..           ...          ...  \n",
      "214          NaN            3  \n",
      "215          NaN           38  \n",
      "216          NaN          126  \n",
      "217          NaN           12  \n",
      "218          NaN            2  \n",
      "\n",
      "[219 rows x 6 columns]\n",
      "DataFrame saved to pickup_slots.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the calculated loads\n",
    "loads = []\n",
    "\n",
    "for warehouse_id, slot in results_df.groupby('warehouse_id'):\n",
    "    for index, row in slot.iterrows():\n",
    "        warehouse_id = row['warehouse_id']\n",
    "        slot_start_time = row['pickup_start_time']\n",
    "        slot_end_time = row['pickup_end_time']\n",
    "\n",
    "        filtered_df = df[(df['warehouse_id'] == warehouse_id) &\n",
    "                         (df['pickuptime'] >= slot_start_time) &\n",
    "                         (df['pickuptime'] <= slot_end_time)]\n",
    "\n",
    "        # Count the number of awbs within the slot time range\n",
    "        load = len(filtered_df)\n",
    "        \n",
    "        # Append the calculated load count to the list\n",
    "        loads.append(load)\n",
    "\n",
    "# Add the 'load' column to results_df\n",
    "results_df['actual_load'] = loads\n",
    "\n",
    "# Print or display the updated DataFrame with the 'load' column\n",
    "print(results_df)\n",
    "\n",
    "# Save DataFrame to Excel\n",
    "excel_file = 'pickup_slots.xlsx'\n",
    "results_df.to_excel(excel_file, index=False)\n",
    "\n",
    "print(f\"DataFrame saved to {excel_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     warehouse_id   pickup_start_time     pickup_end_time  slot_duration  \\\n",
      "0              83 2024-07-06 16:49:33 2024-07-06 16:55:17              6   \n",
      "0              83 2024-07-06 16:49:33 2024-07-06 16:55:17              6   \n",
      "0              83 2024-07-06 16:49:33 2024-07-06 16:55:17              6   \n",
      "0              83 2024-07-06 16:49:33 2024-07-06 16:55:17              6   \n",
      "0              83 2024-07-06 16:49:33 2024-07-06 16:55:17              6   \n",
      "..            ...                 ...                 ...            ...   \n",
      "217          2147 2024-07-06 12:23:09 2024-07-06 12:25:42              3   \n",
      "217          2147 2024-07-06 12:23:09 2024-07-06 12:25:42              3   \n",
      "217          2147 2024-07-06 12:23:09 2024-07-06 12:25:42              3   \n",
      "218          2151 2024-07-06 16:46:59 2024-07-06 16:47:04              1   \n",
      "218          2151 2024-07-06 16:46:59 2024-07-06 16:47:04              1   \n",
      "\n",
      "     gap_to_next          awbs  \n",
      "0            NaN  GS1785205670  \n",
      "0            NaN  GS2006391816  \n",
      "0            NaN  GS1166207635  \n",
      "0            NaN  GS1053787147  \n",
      "0            NaN  GS1758550671  \n",
      "..           ...           ...  \n",
      "217          NaN  GS1945488003  \n",
      "217          NaN  GS2022778763  \n",
      "217          NaN  GS1524706122  \n",
      "218          NaN  GS1812158876  \n",
      "218          NaN  GS1755804579  \n",
      "\n",
      "[17431 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 18:27:18,001| ERROR   | Socket exception: Operation timed out (60)\n",
      "2024-07-08 18:27:18,003| ERROR   | Socket exception: Operation timed out (60)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for warehouse, group in df.groupby('warehouse_id'):\n",
    "    group = group.reset_index(drop=True)\n",
    "\n",
    "    pickup_start_time = group.loc[0, 'pickuptime']\n",
    "    awb_start_times = {group.loc[0, 'awb']: pickup_start_time}\n",
    "\n",
    "    for i in range(1, len(group)):\n",
    "        current_time = group.loc[i, 'pickuptime']\n",
    "        previous_time = group.loc[i - 1, 'pickuptime']\n",
    "\n",
    "        # Check the difference between current and previous pickuptime\n",
    "        if (current_time - previous_time).total_seconds() > 3600:  # More than one hour\n",
    "            # End the current pickup slot and start a new one\n",
    "            results.append({\n",
    "                'warehouse_id': warehouse,\n",
    "                'pickup_start_time': pickup_start_time,\n",
    "                'pickup_end_time': previous_time,\n",
    "                'awbs': list(awb_start_times.keys())\n",
    "            })\n",
    "            pickup_start_time = current_time  # Update the start time for the new slot\n",
    "            awb_start_times = {}\n",
    "\n",
    "        awb_start_times[group.loc[i, 'awb']] = pickup_start_time\n",
    "\n",
    "    # Append the last slot for the warehouse\n",
    "    results.append({\n",
    "        'warehouse_id': warehouse,\n",
    "        'pickup_start_time': pickup_start_time,\n",
    "        'pickup_end_time': group.loc[len(group) - 1, 'pickuptime'],\n",
    "        'awbs': list(awb_start_times.keys())\n",
    "    })\n",
    "\n",
    "# Create DataFrame from results list\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Calculate slot_duration in minutes\n",
    "results_df['slot_duration'] = ((results_df['pickup_end_time'] - results_df['pickup_start_time']).dt.total_seconds() / 60).apply(math.ceil)\n",
    "\n",
    "# Sort DataFrame by warehouse_id and pickup_start_time (if not already sorted)\n",
    "results_df.sort_values(by=['warehouse_id', 'pickup_start_time'], inplace=True)\n",
    "\n",
    "# Calculate gaps between pickup slots in minutes\n",
    "results_df['gap_to_next'] = results_df.groupby('warehouse_id')['pickup_start_time'].shift(-1) - results_df['pickup_end_time']\n",
    "results_df['gap_to_next'] = (results_df['gap_to_next'].dt.total_seconds() / 60)\n",
    "results_df['gap_to_next'].fillna(0, inplace=True)\n",
    "results_df['gap_to_next'] = (results_df['gap_to_next'].astype(int) + 1).replace(1, np.nan)\n",
    "\n",
    "# Explode the 'awbs' column to separate rows for each AWB\n",
    "results_df_exploded = results_df.explode('awbs')\n",
    "\n",
    "print(results_df_exploded[['warehouse_id', 'pickup_start_time', 'pickup_end_time', 'slot_duration', 'gap_to_next', 'awbs']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
